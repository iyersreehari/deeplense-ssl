{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b916b2-d08b-405d-b697-2361be064216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../ssl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310878f1-fa86-4bf3-a8ab-156f6ce31893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import plot_history\n",
    "from utils.eval import hyperparam_grid_finetune\n",
    "import torchvision.transforms as Transforms\n",
    "from augmentations.utils import MinMaxScaling\n",
    "from utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99055f2b-141b-45ae-a1d1-eec436545d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d8e1bc-7112-4801-b0fd-8cca8e05460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"./expt13_models/epoch_800_accknn_85.979730_checkpoint.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ac7bb2-529a-4c14-821a-851d643692b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(ckpt_path, plt_save_path=\"./train_history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d3fcad4-0581-409a-9b89-9b5832e80b37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================\n",
      "Iter 1\n",
      "lr: 0.0001, momentum: 0.9, weight_decay: 0.0, num_epochs: 20\n",
      "\n",
      "[0/20] Train Loss: 0.3945, Val Loss: 0.2975, Val Accuracy: 86.82%\n",
      "\n",
      "[1/20] Train Loss: 0.2952, Val Loss: 0.3116, Val Accuracy: 89.70%\n",
      "\n",
      "[2/20] Train Loss: 0.2952, Val Loss: 0.3116, Val Accuracy: 89.70%\n",
      "\n",
      "[3/20] Train Loss: 0.2952, Val Loss: 0.3116, Val Accuracy: 89.70%\n",
      "\n",
      "[4/20] Train Loss: 0.2952, Val Loss: 0.3116, Val Accuracy: 89.70%\n",
      "\n",
      "[5/20] Train Loss: 0.2952, Val Loss: 0.3116, Val Accuracy: 89.70%\n",
      "\n",
      "[6/20] Train Loss: 0.1837, Val Loss: 0.2904, Val Accuracy: 90.20%\n",
      "\n",
      "[7/20] Train Loss: 0.1580, Val Loss: 0.2289, Val Accuracy: 90.54%\n",
      "\n",
      "[8/20] Train Loss: 0.1373, Val Loss: 0.2589, Val Accuracy: 90.71%\n",
      "\n",
      "[9/20] Train Loss: 0.1373, Val Loss: 0.2589, Val Accuracy: 90.71%\n",
      "\n",
      "[10/20] Train Loss: 0.1093, Val Loss: 0.2990, Val Accuracy: 91.05%\n",
      "\n",
      "[11/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[12/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[13/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[14/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[15/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[16/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[17/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[18/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[19/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       260        |          33         |\n",
      "| true nonlenses |        23        |         277         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 90.5565% |\n",
      "|    loss   |  0.0067  |\n",
      "| auc score |  0.9705  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.9187  | 0.8874 |  0.9028 |   293   |\n",
      "|   nonlenses    |   0.8935  | 0.9233 |  0.9082 |   300   |\n",
      "| macro averaged |   0.9061  | 0.9054 |  0.9055 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================\n",
      "Iter 2\n",
      "lr: 1e-05, momentum: 0.9, weight_decay: 0.0, num_epochs: 20\n",
      "\n",
      "[0/20] Train Loss: 0.4307, Val Loss: 0.3277, Val Accuracy: 86.66%\n",
      "\n",
      "[1/20] Train Loss: 0.2958, Val Loss: 0.2612, Val Accuracy: 88.85%\n",
      "\n",
      "[2/20] Train Loss: 0.2646, Val Loss: 0.2660, Val Accuracy: 89.02%\n",
      "\n",
      "[3/20] Train Loss: 0.2332, Val Loss: 0.2802, Val Accuracy: 90.03%\n",
      "\n",
      "[4/20] Train Loss: 0.2332, Val Loss: 0.2802, Val Accuracy: 90.03%\n",
      "\n",
      "[5/20] Train Loss: 0.2332, Val Loss: 0.2802, Val Accuracy: 90.03%\n",
      "\n",
      "[6/20] Train Loss: 0.2332, Val Loss: 0.2802, Val Accuracy: 90.03%\n",
      "\n",
      "[7/20] Train Loss: 0.2332, Val Loss: 0.2802, Val Accuracy: 90.03%\n",
      "\n",
      "[8/20] Train Loss: 0.2332, Val Loss: 0.2802, Val Accuracy: 90.03%\n",
      "\n",
      "[9/20] Train Loss: 0.2332, Val Loss: 0.2802, Val Accuracy: 90.03%\n",
      "\n",
      "[10/20] Train Loss: 0.2332, Val Loss: 0.2802, Val Accuracy: 90.03%\n",
      "\n",
      "[11/20] Train Loss: 0.0793, Val Loss: 0.3296, Val Accuracy: 90.20%\n",
      "\n",
      "[12/20] Train Loss: 0.0793, Val Loss: 0.3296, Val Accuracy: 90.20%\n",
      "\n",
      "[13/20] Train Loss: 0.0793, Val Loss: 0.3296, Val Accuracy: 90.20%\n",
      "\n",
      "[14/20] Train Loss: 0.0793, Val Loss: 0.3296, Val Accuracy: 90.20%\n",
      "\n",
      "[15/20] Train Loss: 0.0793, Val Loss: 0.3296, Val Accuracy: 90.20%\n",
      "\n",
      "[16/20] Train Loss: 0.0793, Val Loss: 0.3296, Val Accuracy: 90.20%\n",
      "\n",
      "[17/20] Train Loss: 0.0793, Val Loss: 0.3296, Val Accuracy: 90.20%\n",
      "\n",
      "[18/20] Train Loss: 0.0793, Val Loss: 0.3296, Val Accuracy: 90.20%\n",
      "\n",
      "[19/20] Train Loss: 0.0793, Val Loss: 0.3296, Val Accuracy: 90.20%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       259        |          34         |\n",
      "| true nonlenses |        26        |         274         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 89.8820% |\n",
      "|    loss   |  0.0117  |\n",
      "| auc score |  0.9594  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.9088  | 0.8840 |  0.8962 |   293   |\n",
      "|   nonlenses    |   0.8896  | 0.9133 |  0.9013 |   300   |\n",
      "| macro averaged |   0.8992  | 0.8986 |  0.8988 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 3\n",
      "lr: 1e-06, momentum: 0.9, weight_decay: 0.0, num_epochs: 20\n",
      "\n",
      "[0/20] Train Loss: 0.6192, Val Loss: 0.5269, Val Accuracy: 78.04%\n",
      "\n",
      "[1/20] Train Loss: 0.4979, Val Loss: 0.4386, Val Accuracy: 83.28%\n",
      "\n",
      "[2/20] Train Loss: 0.4320, Val Loss: 0.3966, Val Accuracy: 84.29%\n",
      "\n",
      "[3/20] Train Loss: 0.3951, Val Loss: 0.3718, Val Accuracy: 85.14%\n",
      "\n",
      "[4/20] Train Loss: 0.3951, Val Loss: 0.3718, Val Accuracy: 85.14%\n",
      "\n",
      "[5/20] Train Loss: 0.3951, Val Loss: 0.3718, Val Accuracy: 85.14%\n",
      "\n",
      "[6/20] Train Loss: 0.3369, Val Loss: 0.3334, Val Accuracy: 85.30%\n",
      "\n",
      "[7/20] Train Loss: 0.3289, Val Loss: 0.3248, Val Accuracy: 85.47%\n",
      "\n",
      "[8/20] Train Loss: 0.3193, Val Loss: 0.3175, Val Accuracy: 86.49%\n",
      "\n",
      "[9/20] Train Loss: 0.3128, Val Loss: 0.3118, Val Accuracy: 86.66%\n",
      "\n",
      "[10/20] Train Loss: 0.3128, Val Loss: 0.3118, Val Accuracy: 86.66%\n",
      "\n",
      "[11/20] Train Loss: 0.3035, Val Loss: 0.3032, Val Accuracy: 86.99%\n",
      "\n",
      "[12/20] Train Loss: 0.3047, Val Loss: 0.3005, Val Accuracy: 87.33%\n",
      "\n",
      "[13/20] Train Loss: 0.3047, Val Loss: 0.3005, Val Accuracy: 87.33%\n",
      "\n",
      "[14/20] Train Loss: 0.3047, Val Loss: 0.3005, Val Accuracy: 87.33%\n",
      "\n",
      "[15/20] Train Loss: 0.3047, Val Loss: 0.3005, Val Accuracy: 87.33%\n",
      "\n",
      "[16/20] Train Loss: 0.2976, Val Loss: 0.2952, Val Accuracy: 87.67%\n",
      "\n",
      "[17/20] Train Loss: 0.2976, Val Loss: 0.2952, Val Accuracy: 87.67%\n",
      "\n",
      "[18/20] Train Loss: 0.2976, Val Loss: 0.2952, Val Accuracy: 87.67%\n",
      "\n",
      "[19/20] Train Loss: 0.2976, Val Loss: 0.2952, Val Accuracy: 87.67%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       244        |          49         |\n",
      "| true nonlenses |        37        |         263         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 85.4975% |\n",
      "|    loss   |  0.0111  |\n",
      "| auc score |  0.9381  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8683  | 0.8328 |  0.8502 |   293   |\n",
      "|   nonlenses    |   0.8429  | 0.8767 |  0.8595 |   300   |\n",
      "| macro averaged |   0.8556  | 0.8547 |  0.8548 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 4\n",
      "lr: 1e-07, momentum: 0.9, weight_decay: 0.0, num_epochs: 20\n",
      "\n",
      "[0/20] Train Loss: 0.8367, Val Loss: 0.8542, Val Accuracy: 38.01%\n",
      "\n",
      "[1/20] Train Loss: 0.7887, Val Loss: 0.7979, Val Accuracy: 39.02%\n",
      "\n",
      "[2/20] Train Loss: 0.7430, Val Loss: 0.7480, Val Accuracy: 39.86%\n",
      "\n",
      "[3/20] Train Loss: 0.7059, Val Loss: 0.7039, Val Accuracy: 44.26%\n",
      "\n",
      "[4/20] Train Loss: 0.6713, Val Loss: 0.6663, Val Accuracy: 51.01%\n",
      "\n",
      "[5/20] Train Loss: 0.6443, Val Loss: 0.6365, Val Accuracy: 57.43%\n",
      "\n",
      "[6/20] Train Loss: 0.6211, Val Loss: 0.6113, Val Accuracy: 63.01%\n",
      "\n",
      "[7/20] Train Loss: 0.6019, Val Loss: 0.5910, Val Accuracy: 66.89%\n",
      "\n",
      "[8/20] Train Loss: 0.5858, Val Loss: 0.5743, Val Accuracy: 69.09%\n",
      "\n",
      "[9/20] Train Loss: 0.5755, Val Loss: 0.5604, Val Accuracy: 71.79%\n",
      "\n",
      "[10/20] Train Loss: 0.5641, Val Loss: 0.5495, Val Accuracy: 72.80%\n",
      "\n",
      "[11/20] Train Loss: 0.5565, Val Loss: 0.5408, Val Accuracy: 74.83%\n",
      "\n",
      "[12/20] Train Loss: 0.5494, Val Loss: 0.5342, Val Accuracy: 75.34%\n",
      "\n",
      "[13/20] Train Loss: 0.5494, Val Loss: 0.5342, Val Accuracy: 75.34%\n",
      "\n",
      "[14/20] Train Loss: 0.5404, Val Loss: 0.5251, Val Accuracy: 76.01%\n",
      "\n",
      "[15/20] Train Loss: 0.5368, Val Loss: 0.5224, Val Accuracy: 76.52%\n",
      "\n",
      "[16/20] Train Loss: 0.5354, Val Loss: 0.5207, Val Accuracy: 76.69%\n",
      "\n",
      "[17/20] Train Loss: 0.5333, Val Loss: 0.5197, Val Accuracy: 76.86%\n",
      "\n",
      "[18/20] Train Loss: 0.5337, Val Loss: 0.5193, Val Accuracy: 77.20%\n",
      "\n",
      "[19/20] Train Loss: 0.5337, Val Loss: 0.5193, Val Accuracy: 77.20%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       208        |          85         |\n",
      "| true nonlenses |        54        |         246         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 76.5599% |\n",
      "|    loss   |  0.0289  |\n",
      "| auc score |  0.8233  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.7939  | 0.7099 |  0.7495 |   293   |\n",
      "|   nonlenses    |   0.7432  | 0.8200 |  0.7797 |   300   |\n",
      "| macro averaged |   0.7685  | 0.7649 |  0.7646 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 5\n",
      "lr: 0.0001, momentum: 0.9, weight_decay: 0.0005, num_epochs: 20\n",
      "\n",
      "[0/20] Train Loss: 0.3852, Val Loss: 0.3034, Val Accuracy: 88.85%\n",
      "\n",
      "[1/20] Train Loss: 0.3010, Val Loss: 0.2740, Val Accuracy: 90.20%\n",
      "\n",
      "[2/20] Train Loss: 0.3010, Val Loss: 0.2740, Val Accuracy: 90.20%\n",
      "\n",
      "[3/20] Train Loss: 0.3010, Val Loss: 0.2740, Val Accuracy: 90.20%\n",
      "\n",
      "[4/20] Train Loss: 0.2027, Val Loss: 0.2549, Val Accuracy: 90.71%\n",
      "\n",
      "[5/20] Train Loss: 0.2027, Val Loss: 0.2549, Val Accuracy: 90.71%\n",
      "\n",
      "[6/20] Train Loss: 0.2027, Val Loss: 0.2549, Val Accuracy: 90.71%\n",
      "\n",
      "[7/20] Train Loss: 0.2027, Val Loss: 0.2549, Val Accuracy: 90.71%\n",
      "\n",
      "[8/20] Train Loss: 0.2027, Val Loss: 0.2549, Val Accuracy: 90.71%\n",
      "\n",
      "[9/20] Train Loss: 0.2027, Val Loss: 0.2549, Val Accuracy: 90.71%\n",
      "\n",
      "[10/20] Train Loss: 0.2027, Val Loss: 0.2549, Val Accuracy: 90.71%\n",
      "\n",
      "[11/20] Train Loss: 0.0539, Val Loss: 0.3178, Val Accuracy: 91.39%\n",
      "\n",
      "[12/20] Train Loss: 0.0539, Val Loss: 0.3178, Val Accuracy: 91.39%\n",
      "\n",
      "[13/20] Train Loss: 0.0539, Val Loss: 0.3178, Val Accuracy: 91.39%\n",
      "\n",
      "[14/20] Train Loss: 0.0539, Val Loss: 0.3178, Val Accuracy: 91.39%\n",
      "\n",
      "[15/20] Train Loss: 0.0539, Val Loss: 0.3178, Val Accuracy: 91.39%\n",
      "\n",
      "[16/20] Train Loss: 0.0539, Val Loss: 0.3178, Val Accuracy: 91.39%\n",
      "\n",
      "[17/20] Train Loss: 0.0539, Val Loss: 0.3178, Val Accuracy: 91.39%\n",
      "\n",
      "[18/20] Train Loss: 0.0539, Val Loss: 0.3178, Val Accuracy: 91.39%\n",
      "\n",
      "[19/20] Train Loss: 0.0539, Val Loss: 0.3178, Val Accuracy: 91.39%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       262        |          31         |\n",
      "| true nonlenses |        26        |         274         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 90.3879% |\n",
      "|    loss   |  0.0086  |\n",
      "| auc score |  0.9707  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.9097  | 0.8942 |  0.9019 |   293   |\n",
      "|   nonlenses    |   0.8984  | 0.9133 |  0.9058 |   300   |\n",
      "| macro averaged |   0.9040  | 0.9038 |  0.9038 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 6\n",
      "lr: 1e-05, momentum: 0.9, weight_decay: 0.0005, num_epochs: 20\n",
      "\n",
      "[0/20] Train Loss: 0.4558, Val Loss: 0.3027, Val Accuracy: 87.50%\n",
      "\n",
      "[1/20] Train Loss: 0.2972, Val Loss: 0.2713, Val Accuracy: 89.36%\n",
      "\n",
      "[2/20] Train Loss: 0.2972, Val Loss: 0.2713, Val Accuracy: 89.36%\n",
      "\n",
      "[3/20] Train Loss: 0.2972, Val Loss: 0.2713, Val Accuracy: 89.36%\n",
      "\n",
      "[4/20] Train Loss: 0.2972, Val Loss: 0.2713, Val Accuracy: 89.36%\n",
      "\n",
      "[5/20] Train Loss: 0.2016, Val Loss: 0.2327, Val Accuracy: 91.22%\n",
      "\n",
      "[6/20] Train Loss: 0.2016, Val Loss: 0.2327, Val Accuracy: 91.22%\n",
      "\n",
      "[7/20] Train Loss: 0.2016, Val Loss: 0.2327, Val Accuracy: 91.22%\n",
      "\n",
      "[8/20] Train Loss: 0.2016, Val Loss: 0.2327, Val Accuracy: 91.22%\n",
      "\n",
      "[9/20] Train Loss: 0.2016, Val Loss: 0.2327, Val Accuracy: 91.22%\n",
      "\n",
      "[10/20] Train Loss: 0.2016, Val Loss: 0.2327, Val Accuracy: 91.22%\n",
      "\n",
      "[11/20] Train Loss: 0.2016, Val Loss: 0.2327, Val Accuracy: 91.22%\n",
      "\n",
      "[12/20] Train Loss: 0.2016, Val Loss: 0.2327, Val Accuracy: 91.22%\n",
      "\n",
      "[13/20] Train Loss: 0.0769, Val Loss: 0.3061, Val Accuracy: 91.39%\n",
      "\n",
      "[14/20] Train Loss: 0.0769, Val Loss: 0.3061, Val Accuracy: 91.39%\n",
      "\n",
      "[15/20] Train Loss: 0.0769, Val Loss: 0.3061, Val Accuracy: 91.39%\n",
      "\n",
      "[16/20] Train Loss: 0.0769, Val Loss: 0.3061, Val Accuracy: 91.39%\n",
      "\n",
      "[17/20] Train Loss: 0.0769, Val Loss: 0.3061, Val Accuracy: 91.39%\n",
      "\n",
      "[18/20] Train Loss: 0.0769, Val Loss: 0.3061, Val Accuracy: 91.39%\n",
      "\n",
      "[19/20] Train Loss: 0.0769, Val Loss: 0.3061, Val Accuracy: 91.39%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       262        |          31         |\n",
      "| true nonlenses |        26        |         274         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 90.3879% |\n",
      "|    loss   |  0.0169  |\n",
      "| auc score |  0.9657  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.9097  | 0.8942 |  0.9019 |   293   |\n",
      "|   nonlenses    |   0.8984  | 0.9133 |  0.9058 |   300   |\n",
      "| macro averaged |   0.9040  | 0.9038 |  0.9038 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 7\n",
      "lr: 1e-06, momentum: 0.9, weight_decay: 0.0005, num_epochs: 20\n",
      "\n",
      "[0/20] Train Loss: 0.8886, Val Loss: 0.6623, Val Accuracy: 66.72%\n",
      "\n",
      "[1/20] Train Loss: 0.6443, Val Loss: 0.5045, Val Accuracy: 77.70%\n",
      "\n",
      "[2/20] Train Loss: 0.4998, Val Loss: 0.4294, Val Accuracy: 83.45%\n",
      "\n",
      "[3/20] Train Loss: 0.4316, Val Loss: 0.3988, Val Accuracy: 84.97%\n",
      "\n",
      "[4/20] Train Loss: 0.4316, Val Loss: 0.3988, Val Accuracy: 84.97%\n",
      "\n",
      "[5/20] Train Loss: 0.4316, Val Loss: 0.3988, Val Accuracy: 84.97%\n",
      "\n",
      "[6/20] Train Loss: 0.3719, Val Loss: 0.3642, Val Accuracy: 85.47%\n",
      "\n",
      "[7/20] Train Loss: 0.3719, Val Loss: 0.3642, Val Accuracy: 85.47%\n",
      "\n",
      "[8/20] Train Loss: 0.3569, Val Loss: 0.3596, Val Accuracy: 85.81%\n",
      "\n",
      "[9/20] Train Loss: 0.3486, Val Loss: 0.3516, Val Accuracy: 85.98%\n",
      "\n",
      "[10/20] Train Loss: 0.3486, Val Loss: 0.3516, Val Accuracy: 85.98%\n",
      "\n",
      "[11/20] Train Loss: 0.3362, Val Loss: 0.3448, Val Accuracy: 86.32%\n",
      "\n",
      "[12/20] Train Loss: 0.3369, Val Loss: 0.3423, Val Accuracy: 86.49%\n",
      "\n",
      "[13/20] Train Loss: 0.3369, Val Loss: 0.3423, Val Accuracy: 86.49%\n",
      "\n",
      "[14/20] Train Loss: 0.3369, Val Loss: 0.3423, Val Accuracy: 86.49%\n",
      "\n",
      "[15/20] Train Loss: 0.3369, Val Loss: 0.3423, Val Accuracy: 86.49%\n",
      "\n",
      "[16/20] Train Loss: 0.3303, Val Loss: 0.3381, Val Accuracy: 86.82%\n",
      "\n",
      "[17/20] Train Loss: 0.3303, Val Loss: 0.3381, Val Accuracy: 86.82%\n",
      "\n",
      "[18/20] Train Loss: 0.3303, Val Loss: 0.3381, Val Accuracy: 86.82%\n",
      "\n",
      "[19/20] Train Loss: 0.3303, Val Loss: 0.3381, Val Accuracy: 86.82%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       249        |          44         |\n",
      "| true nonlenses |        47        |         253         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 84.6543% |\n",
      "|    loss   |  0.0150  |\n",
      "| auc score |  0.9281  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8412  | 0.8498 |  0.8455 |   293   |\n",
      "|   nonlenses    |   0.8519  | 0.8433 |  0.8476 |   300   |\n",
      "| macro averaged |   0.8465  | 0.8466 |  0.8465 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 8\n",
      "lr: 1e-07, momentum: 0.9, weight_decay: 0.0005, num_epochs: 20\n",
      "\n",
      "[0/20] Train Loss: 1.4258, Val Loss: 1.4818, Val Accuracy: 25.68%\n",
      "\n",
      "[1/20] Train Loss: 1.4258, Val Loss: 1.4818, Val Accuracy: 25.68%\n",
      "\n",
      "[2/20] Train Loss: 1.4258, Val Loss: 1.4818, Val Accuracy: 25.68%\n",
      "\n",
      "[3/20] Train Loss: 1.2461, Val Loss: 1.2713, Val Accuracy: 26.18%\n",
      "\n",
      "[4/20] Train Loss: 1.1873, Val Loss: 1.2081, Val Accuracy: 26.69%\n",
      "\n",
      "[5/20] Train Loss: 1.1338, Val Loss: 1.1508, Val Accuracy: 28.04%\n",
      "\n",
      "[6/20] Train Loss: 1.0896, Val Loss: 1.1004, Val Accuracy: 28.55%\n",
      "\n",
      "[7/20] Train Loss: 1.0896, Val Loss: 1.1004, Val Accuracy: 28.55%\n",
      "\n",
      "[8/20] Train Loss: 1.0139, Val Loss: 1.0194, Val Accuracy: 29.05%\n",
      "\n",
      "[9/20] Train Loss: 0.9838, Val Loss: 0.9878, Val Accuracy: 29.90%\n",
      "\n",
      "[10/20] Train Loss: 0.9621, Val Loss: 0.9613, Val Accuracy: 30.91%\n",
      "\n",
      "[11/20] Train Loss: 0.9397, Val Loss: 0.9402, Val Accuracy: 31.25%\n",
      "\n",
      "[12/20] Train Loss: 0.9231, Val Loss: 0.9232, Val Accuracy: 31.42%\n",
      "\n",
      "[13/20] Train Loss: 0.9103, Val Loss: 0.9100, Val Accuracy: 31.76%\n",
      "\n",
      "[14/20] Train Loss: 0.9011, Val Loss: 0.9002, Val Accuracy: 31.93%\n",
      "\n",
      "[15/20] Train Loss: 0.8958, Val Loss: 0.8935, Val Accuracy: 32.43%\n",
      "\n",
      "[16/20] Train Loss: 0.8896, Val Loss: 0.8890, Val Accuracy: 32.77%\n",
      "\n",
      "[17/20] Train Loss: 0.8859, Val Loss: 0.8865, Val Accuracy: 32.94%\n",
      "\n",
      "[18/20] Train Loss: 0.8859, Val Loss: 0.8865, Val Accuracy: 32.94%\n",
      "\n",
      "[19/20] Train Loss: 0.8859, Val Loss: 0.8865, Val Accuracy: 32.94%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       144        |         149         |\n",
      "| true nonlenses |       229        |          71         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 36.2563% |\n",
      "|    loss   |  0.0500  |\n",
      "| auc score |  0.3843  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.3861  | 0.4915 |  0.4324 |   293   |\n",
      "|   nonlenses    |   0.3227  | 0.2367 |  0.2731 |   300   |\n",
      "| macro averaged |   0.3544  | 0.3641 |  0.3528 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 9\n",
      "lr: 0.0001, momentum: 0.9, weight_decay: 5e-05, num_epochs: 20\n",
      "\n",
      "[0/20] Train Loss: 0.4017, Val Loss: 0.3959, Val Accuracy: 83.95%\n",
      "\n",
      "[1/20] Train Loss: 0.3268, Val Loss: 0.2856, Val Accuracy: 88.68%\n",
      "\n",
      "[2/20] Train Loss: 0.3268, Val Loss: 0.2856, Val Accuracy: 88.68%\n",
      "\n",
      "[3/20] Train Loss: 0.3268, Val Loss: 0.2856, Val Accuracy: 88.68%\n",
      "\n",
      "[4/20] Train Loss: 0.2515, Val Loss: 0.2557, Val Accuracy: 90.37%\n",
      "\n",
      "[5/20] Train Loss: 0.2515, Val Loss: 0.2557, Val Accuracy: 90.37%\n",
      "\n",
      "[6/20] Train Loss: 0.2515, Val Loss: 0.2557, Val Accuracy: 90.37%\n",
      "\n",
      "[7/20] Train Loss: 0.2515, Val Loss: 0.2557, Val Accuracy: 90.37%\n",
      "\n",
      "[8/20] Train Loss: 0.2515, Val Loss: 0.2557, Val Accuracy: 90.37%\n",
      "\n",
      "[9/20] Train Loss: 0.2515, Val Loss: 0.2557, Val Accuracy: 90.37%\n",
      "\n",
      "[10/20] Train Loss: 0.2515, Val Loss: 0.2557, Val Accuracy: 90.37%\n",
      "\n",
      "[11/20] Train Loss: 0.2515, Val Loss: 0.2557, Val Accuracy: 90.37%\n",
      "\n",
      "[12/20] Train Loss: 0.2515, Val Loss: 0.2557, Val Accuracy: 90.37%\n",
      "\n",
      "[13/20] Train Loss: 0.2515, Val Loss: 0.2557, Val Accuracy: 90.37%\n",
      "\n",
      "[14/20] Train Loss: 0.2515, Val Loss: 0.2557, Val Accuracy: 90.37%\n",
      "\n",
      "[15/20] Train Loss: 0.0200, Val Loss: 0.4039, Val Accuracy: 90.88%\n",
      "\n",
      "[16/20] Train Loss: 0.0200, Val Loss: 0.4039, Val Accuracy: 90.88%\n",
      "\n",
      "[17/20] Train Loss: 0.0200, Val Loss: 0.4039, Val Accuracy: 90.88%\n",
      "\n",
      "[18/20] Train Loss: 0.0200, Val Loss: 0.4039, Val Accuracy: 90.88%\n",
      "\n",
      "[19/20] Train Loss: 0.0200, Val Loss: 0.4039, Val Accuracy: 90.88%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       270        |          23         |\n",
      "| true nonlenses |        28        |         272         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 91.3997% |\n",
      "|    loss   |  0.0030  |\n",
      "| auc score |  0.9656  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.9060  | 0.9215 |  0.9137 |   293   |\n",
      "|   nonlenses    |   0.9220  | 0.9067 |  0.9143 |   300   |\n",
      "| macro averaged |   0.9140  | 0.9141 |  0.9140 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================\n",
      "Iter 10\n",
      "lr: 1e-05, momentum: 0.9, weight_decay: 5e-05, num_epochs: 20\n",
      "\n",
      "[0/20] Train Loss: 0.4466, Val Loss: 0.3341, Val Accuracy: 86.82%\n",
      "\n",
      "[1/20] Train Loss: 0.3079, Val Loss: 0.2920, Val Accuracy: 87.84%\n",
      "\n",
      "[2/20] Train Loss: 0.2695, Val Loss: 0.2594, Val Accuracy: 89.19%\n",
      "\n",
      "[3/20] Train Loss: 0.2419, Val Loss: 0.2482, Val Accuracy: 89.53%\n",
      "\n",
      "[4/20] Train Loss: 0.2136, Val Loss: 0.2238, Val Accuracy: 90.20%\n",
      "\n",
      "[5/20] Train Loss: 0.2136, Val Loss: 0.2238, Val Accuracy: 90.20%\n",
      "\n",
      "[6/20] Train Loss: 0.1709, Val Loss: 0.2485, Val Accuracy: 90.54%\n",
      "\n",
      "[7/20] Train Loss: 0.1709, Val Loss: 0.2485, Val Accuracy: 90.54%\n",
      "\n",
      "[8/20] Train Loss: 0.1261, Val Loss: 0.2576, Val Accuracy: 91.22%\n",
      "\n",
      "[9/20] Train Loss: 0.1261, Val Loss: 0.2576, Val Accuracy: 91.22%\n",
      "\n",
      "[10/20] Train Loss: 0.1261, Val Loss: 0.2576, Val Accuracy: 91.22%\n",
      "\n",
      "[11/20] Train Loss: 0.1261, Val Loss: 0.2576, Val Accuracy: 91.22%\n",
      "\n",
      "[12/20] Train Loss: 0.1261, Val Loss: 0.2576, Val Accuracy: 91.22%\n",
      "\n",
      "[13/20] Train Loss: 0.1261, Val Loss: 0.2576, Val Accuracy: 91.22%\n",
      "\n",
      "[14/20] Train Loss: 0.1261, Val Loss: 0.2576, Val Accuracy: 91.22%\n",
      "\n",
      "[15/20] Train Loss: 0.1261, Val Loss: 0.2576, Val Accuracy: 91.22%\n",
      "\n",
      "[16/20] Train Loss: 0.1261, Val Loss: 0.2576, Val Accuracy: 91.22%\n",
      "\n",
      "[17/20] Train Loss: 0.1261, Val Loss: 0.2576, Val Accuracy: 91.22%\n",
      "\n",
      "[18/20] Train Loss: 0.1261, Val Loss: 0.2576, Val Accuracy: 91.22%\n",
      "\n",
      "[19/20] Train Loss: 0.1261, Val Loss: 0.2576, Val Accuracy: 91.22%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       253        |          40         |\n",
      "| true nonlenses |        24        |         276         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 89.2074% |\n",
      "|    loss   |  0.0014  |\n",
      "| auc score |  0.9639  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.9134  | 0.8635 |  0.8877 |   293   |\n",
      "|   nonlenses    |   0.8734  | 0.9200 |  0.8961 |   300   |\n",
      "| macro averaged |   0.8934  | 0.8917 |  0.8919 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================\n",
      "Iter 11\n",
      "lr: 1e-06, momentum: 0.9, weight_decay: 5e-05, num_epochs: 20\n",
      "\n",
      "[0/20] Train Loss: 0.8243, Val Loss: 0.6354, Val Accuracy: 67.23%\n",
      "\n",
      "[1/20] Train Loss: 0.6107, Val Loss: 0.4949, Val Accuracy: 77.87%\n",
      "\n",
      "[2/20] Train Loss: 0.4844, Val Loss: 0.4243, Val Accuracy: 83.95%\n",
      "\n",
      "[3/20] Train Loss: 0.4257, Val Loss: 0.3970, Val Accuracy: 85.30%\n",
      "\n",
      "[4/20] Train Loss: 0.4257, Val Loss: 0.3970, Val Accuracy: 85.30%\n",
      "\n",
      "[5/20] Train Loss: 0.4257, Val Loss: 0.3970, Val Accuracy: 85.30%\n",
      "\n",
      "[6/20] Train Loss: 0.4257, Val Loss: 0.3970, Val Accuracy: 85.30%\n",
      "\n",
      "[7/20] Train Loss: 0.3545, Val Loss: 0.3606, Val Accuracy: 85.64%\n",
      "\n",
      "[8/20] Train Loss: 0.3545, Val Loss: 0.3606, Val Accuracy: 85.64%\n",
      "\n",
      "[9/20] Train Loss: 0.3407, Val Loss: 0.3497, Val Accuracy: 86.15%\n",
      "\n",
      "[10/20] Train Loss: 0.3360, Val Loss: 0.3456, Val Accuracy: 86.32%\n",
      "\n",
      "[11/20] Train Loss: 0.3279, Val Loss: 0.3406, Val Accuracy: 86.66%\n",
      "\n",
      "[12/20] Train Loss: 0.3279, Val Loss: 0.3406, Val Accuracy: 86.66%\n",
      "\n",
      "[13/20] Train Loss: 0.3202, Val Loss: 0.3324, Val Accuracy: 86.82%\n",
      "\n",
      "[14/20] Train Loss: 0.3202, Val Loss: 0.3324, Val Accuracy: 86.82%\n",
      "\n",
      "[15/20] Train Loss: 0.3202, Val Loss: 0.3324, Val Accuracy: 86.82%\n",
      "\n",
      "[16/20] Train Loss: 0.3202, Val Loss: 0.3324, Val Accuracy: 86.82%\n",
      "\n",
      "[17/20] Train Loss: 0.3202, Val Loss: 0.3324, Val Accuracy: 86.82%\n",
      "\n",
      "[18/20] Train Loss: 0.3202, Val Loss: 0.3324, Val Accuracy: 86.82%\n",
      "\n",
      "[19/20] Train Loss: 0.3202, Val Loss: 0.3324, Val Accuracy: 86.82%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       247        |          46         |\n",
      "| true nonlenses |        39        |         261         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 85.6661% |\n",
      "|    loss   |  0.0140  |\n",
      "| auc score |  0.9284  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8636  | 0.8430 |  0.8532 |   293   |\n",
      "|   nonlenses    |   0.8502  | 0.8700 |  0.8600 |   300   |\n",
      "| macro averaged |   0.8569  | 0.8565 |  0.8566 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 12\n",
      "lr: 1e-07, momentum: 0.9, weight_decay: 5e-05, num_epochs: 20\n",
      "\n",
      "[0/20] Train Loss: 1.2431, Val Loss: 1.2831, Val Accuracy: 18.41%\n",
      "\n",
      "[1/20] Train Loss: 1.2053, Val Loss: 1.2400, Val Accuracy: 18.58%\n",
      "\n",
      "[2/20] Train Loss: 1.1681, Val Loss: 1.1996, Val Accuracy: 19.26%\n",
      "\n",
      "[3/20] Train Loss: 1.1340, Val Loss: 1.1611, Val Accuracy: 19.76%\n",
      "\n",
      "[4/20] Train Loss: 1.1002, Val Loss: 1.1256, Val Accuracy: 19.93%\n",
      "\n",
      "[5/20] Train Loss: 1.0723, Val Loss: 1.0928, Val Accuracy: 20.78%\n",
      "\n",
      "[6/20] Train Loss: 1.0456, Val Loss: 1.0635, Val Accuracy: 22.64%\n",
      "\n",
      "[7/20] Train Loss: 1.0208, Val Loss: 1.0377, Val Accuracy: 22.80%\n",
      "\n",
      "[8/20] Train Loss: 1.0009, Val Loss: 1.0158, Val Accuracy: 22.97%\n",
      "\n",
      "[9/20] Train Loss: 0.9837, Val Loss: 0.9974, Val Accuracy: 23.82%\n",
      "\n",
      "[10/20] Train Loss: 0.9703, Val Loss: 0.9828, Val Accuracy: 24.49%\n",
      "\n",
      "[11/20] Train Loss: 0.9584, Val Loss: 0.9704, Val Accuracy: 25.00%\n",
      "\n",
      "[12/20] Train Loss: 0.9473, Val Loss: 0.9603, Val Accuracy: 25.51%\n",
      "\n",
      "[13/20] Train Loss: 0.9416, Val Loss: 0.9527, Val Accuracy: 25.84%\n",
      "\n",
      "[14/20] Train Loss: 0.9357, Val Loss: 0.9469, Val Accuracy: 26.01%\n",
      "\n",
      "[15/20] Train Loss: 0.9304, Val Loss: 0.9428, Val Accuracy: 26.35%\n",
      "\n",
      "[16/20] Train Loss: 0.9296, Val Loss: 0.9400, Val Accuracy: 26.69%\n",
      "\n",
      "[17/20] Train Loss: 0.9271, Val Loss: 0.9385, Val Accuracy: 26.86%\n",
      "\n",
      "[18/20] Train Loss: 0.9271, Val Loss: 0.9385, Val Accuracy: 26.86%\n",
      "\n",
      "[19/20] Train Loss: 0.9271, Val Loss: 0.9385, Val Accuracy: 26.86%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       116        |         177         |\n",
      "| true nonlenses |       237        |          63         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 30.1855% |\n",
      "|    loss   |  0.0497  |\n",
      "| auc score |  0.2381  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.3286  | 0.3959 |  0.3591 |   293   |\n",
      "|   nonlenses    |   0.2625  | 0.2100 |  0.2333 |   300   |\n",
      "| macro averaged |   0.2956  | 0.3030 |  0.2962 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 13\n",
      "lr: 0.0001, momentum: 0.9, weight_decay: 0.0, num_epochs: 50\n",
      "\n",
      "[0/50] Train Loss: 0.3876, Val Loss: 0.2986, Val Accuracy: 89.70%\n",
      "\n",
      "[1/50] Train Loss: 0.3876, Val Loss: 0.2986, Val Accuracy: 89.70%\n",
      "\n",
      "[2/50] Train Loss: 0.3876, Val Loss: 0.2986, Val Accuracy: 89.70%\n",
      "\n",
      "[3/50] Train Loss: 0.3876, Val Loss: 0.2986, Val Accuracy: 89.70%\n",
      "\n",
      "[4/50] Train Loss: 0.2447, Val Loss: 0.2664, Val Accuracy: 89.86%\n",
      "\n",
      "[5/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[6/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[7/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[8/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[9/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[10/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[11/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[12/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[13/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[14/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[15/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[16/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[17/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[18/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[19/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[20/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[21/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[22/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[23/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[24/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[25/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[26/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[27/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[28/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[29/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[30/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[31/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[32/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[33/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[34/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[35/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[36/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[37/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[38/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[39/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[40/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[41/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[42/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[43/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[44/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[45/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[46/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[47/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[48/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "[49/50] Train Loss: 0.1911, Val Loss: 0.2247, Val Accuracy: 91.72%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       255        |          38         |\n",
      "| true nonlenses |        26        |         274         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 89.2074% |\n",
      "|    loss   |  0.0045  |\n",
      "| auc score |  0.9612  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.9075  | 0.8703 |  0.8885 |   293   |\n",
      "|   nonlenses    |   0.8782  | 0.9133 |  0.8954 |   300   |\n",
      "| macro averaged |   0.8928  | 0.8918 |  0.8920 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 14\n",
      "lr: 1e-05, momentum: 0.9, weight_decay: 0.0, num_epochs: 50\n",
      "\n",
      "[0/50] Train Loss: 0.4802, Val Loss: 0.3291, Val Accuracy: 86.66%\n",
      "\n",
      "[1/50] Train Loss: 0.3200, Val Loss: 0.2726, Val Accuracy: 89.36%\n",
      "\n",
      "[2/50] Train Loss: 0.3200, Val Loss: 0.2726, Val Accuracy: 89.36%\n",
      "\n",
      "[3/50] Train Loss: 0.2586, Val Loss: 0.2541, Val Accuracy: 90.20%\n",
      "\n",
      "[4/50] Train Loss: 0.2586, Val Loss: 0.2541, Val Accuracy: 90.20%\n",
      "\n",
      "[5/50] Train Loss: 0.2586, Val Loss: 0.2541, Val Accuracy: 90.20%\n",
      "\n",
      "[6/50] Train Loss: 0.1957, Val Loss: 0.2191, Val Accuracy: 90.88%\n",
      "\n",
      "[7/50] Train Loss: 0.1773, Val Loss: 0.2310, Val Accuracy: 91.05%\n",
      "\n",
      "[8/50] Train Loss: 0.1773, Val Loss: 0.2310, Val Accuracy: 91.05%\n",
      "\n",
      "[9/50] Train Loss: 0.1773, Val Loss: 0.2310, Val Accuracy: 91.05%\n",
      "\n",
      "[10/50] Train Loss: 0.1773, Val Loss: 0.2310, Val Accuracy: 91.05%\n",
      "\n",
      "[11/50] Train Loss: 0.1773, Val Loss: 0.2310, Val Accuracy: 91.05%\n",
      "\n",
      "[12/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[13/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[14/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[15/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[16/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[17/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[18/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[19/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[20/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[21/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[22/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[23/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[24/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[25/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[26/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[27/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[28/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[29/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[30/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[31/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[32/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[33/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[34/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[35/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[36/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[37/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[38/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[39/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[40/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[41/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[42/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[43/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[44/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[45/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[46/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[47/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[48/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "[49/50] Train Loss: 0.0887, Val Loss: 0.2635, Val Accuracy: 92.06%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       260        |          33         |\n",
      "| true nonlenses |        16        |         284         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 91.7369% |\n",
      "|    loss   |  0.0006  |\n",
      "| auc score |  0.9684  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.9420  | 0.8874 |  0.9139 |   293   |\n",
      "|   nonlenses    |   0.8959  | 0.9467 |  0.9206 |   300   |\n",
      "| macro averaged |   0.9190  | 0.9170 |  0.9172 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================\n",
      "Iter 15\n",
      "lr: 1e-06, momentum: 0.9, weight_decay: 0.0, num_epochs: 50\n",
      "\n",
      "[0/50] Train Loss: 0.7142, Val Loss: 0.5434, Val Accuracy: 74.16%\n",
      "\n",
      "[1/50] Train Loss: 0.4836, Val Loss: 0.4339, Val Accuracy: 82.77%\n",
      "\n",
      "[2/50] Train Loss: 0.4273, Val Loss: 0.4005, Val Accuracy: 84.29%\n",
      "\n",
      "[3/50] Train Loss: 0.4273, Val Loss: 0.4005, Val Accuracy: 84.29%\n",
      "\n",
      "[4/50] Train Loss: 0.3789, Val Loss: 0.3677, Val Accuracy: 84.80%\n",
      "\n",
      "[5/50] Train Loss: 0.3631, Val Loss: 0.3571, Val Accuracy: 85.47%\n",
      "\n",
      "[6/50] Train Loss: 0.3631, Val Loss: 0.3571, Val Accuracy: 85.47%\n",
      "\n",
      "[7/50] Train Loss: 0.3368, Val Loss: 0.3372, Val Accuracy: 85.98%\n",
      "\n",
      "[8/50] Train Loss: 0.3257, Val Loss: 0.3287, Val Accuracy: 86.15%\n",
      "\n",
      "[9/50] Train Loss: 0.3160, Val Loss: 0.3214, Val Accuracy: 86.66%\n",
      "\n",
      "[10/50] Train Loss: 0.3117, Val Loss: 0.3153, Val Accuracy: 87.16%\n",
      "\n",
      "[11/50] Train Loss: 0.3035, Val Loss: 0.3099, Val Accuracy: 87.33%\n",
      "\n",
      "[12/50] Train Loss: 0.3035, Val Loss: 0.3099, Val Accuracy: 87.33%\n",
      "\n",
      "[13/50] Train Loss: 0.3035, Val Loss: 0.3099, Val Accuracy: 87.33%\n",
      "\n",
      "[14/50] Train Loss: 0.3035, Val Loss: 0.3099, Val Accuracy: 87.33%\n",
      "\n",
      "[15/50] Train Loss: 0.2786, Val Loss: 0.2910, Val Accuracy: 88.01%\n",
      "\n",
      "[16/50] Train Loss: 0.2786, Val Loss: 0.2910, Val Accuracy: 88.01%\n",
      "\n",
      "[17/50] Train Loss: 0.2786, Val Loss: 0.2910, Val Accuracy: 88.01%\n",
      "\n",
      "[18/50] Train Loss: 0.2786, Val Loss: 0.2910, Val Accuracy: 88.01%\n",
      "\n",
      "[19/50] Train Loss: 0.2786, Val Loss: 0.2910, Val Accuracy: 88.01%\n",
      "\n",
      "[20/50] Train Loss: 0.2556, Val Loss: 0.2796, Val Accuracy: 88.18%\n",
      "\n",
      "[21/50] Train Loss: 0.2540, Val Loss: 0.2745, Val Accuracy: 88.51%\n",
      "\n",
      "[22/50] Train Loss: 0.2540, Val Loss: 0.2745, Val Accuracy: 88.51%\n",
      "\n",
      "[23/50] Train Loss: 0.2540, Val Loss: 0.2745, Val Accuracy: 88.51%\n",
      "\n",
      "[24/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[25/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[26/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[27/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[28/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[29/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[30/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[31/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[32/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[33/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[34/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[35/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[36/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[37/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[38/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[39/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[40/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[41/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[42/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[43/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[44/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[45/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[46/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[47/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[48/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "[49/50] Train Loss: 0.2448, Val Loss: 0.2726, Val Accuracy: 88.85%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       250        |          43         |\n",
      "| true nonlenses |        39        |         261         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 86.1720% |\n",
      "|    loss   |  0.0068  |\n",
      "| auc score |  0.9460  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8651  | 0.8532 |  0.8591 |   293   |\n",
      "|   nonlenses    |   0.8586  | 0.8700 |  0.8642 |   300   |\n",
      "| macro averaged |   0.8618  | 0.8616 |  0.8617 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 16\n",
      "lr: 1e-07, momentum: 0.9, weight_decay: 0.0, num_epochs: 50\n",
      "\n",
      "[0/50] Train Loss: 1.1785, Val Loss: 1.1641, Val Accuracy: 41.55%\n",
      "\n",
      "[1/50] Train Loss: 1.1210, Val Loss: 1.1025, Val Accuracy: 44.76%\n",
      "\n",
      "[2/50] Train Loss: 1.0681, Val Loss: 1.0470, Val Accuracy: 46.28%\n",
      "\n",
      "[3/50] Train Loss: 1.0196, Val Loss: 0.9971, Val Accuracy: 48.14%\n",
      "\n",
      "[4/50] Train Loss: 0.9764, Val Loss: 0.9517, Val Accuracy: 51.01%\n",
      "\n",
      "[5/50] Train Loss: 0.9378, Val Loss: 0.9100, Val Accuracy: 54.39%\n",
      "\n",
      "[6/50] Train Loss: 0.9013, Val Loss: 0.8768, Val Accuracy: 57.26%\n",
      "\n",
      "[7/50] Train Loss: 0.8721, Val Loss: 0.8473, Val Accuracy: 58.78%\n",
      "\n",
      "[8/50] Train Loss: 0.8425, Val Loss: 0.8194, Val Accuracy: 60.47%\n",
      "\n",
      "[9/50] Train Loss: 0.8179, Val Loss: 0.7937, Val Accuracy: 61.82%\n",
      "\n",
      "[10/50] Train Loss: 0.7951, Val Loss: 0.7693, Val Accuracy: 63.85%\n",
      "\n",
      "[11/50] Train Loss: 0.7702, Val Loss: 0.7468, Val Accuracy: 65.03%\n",
      "\n",
      "[12/50] Train Loss: 0.7486, Val Loss: 0.7261, Val Accuracy: 65.37%\n",
      "\n",
      "[13/50] Train Loss: 0.7289, Val Loss: 0.7068, Val Accuracy: 66.55%\n",
      "\n",
      "[14/50] Train Loss: 0.7096, Val Loss: 0.6895, Val Accuracy: 67.40%\n",
      "\n",
      "[15/50] Train Loss: 0.6951, Val Loss: 0.6731, Val Accuracy: 68.58%\n",
      "\n",
      "[16/50] Train Loss: 0.6813, Val Loss: 0.6575, Val Accuracy: 69.09%\n",
      "\n",
      "[17/50] Train Loss: 0.6623, Val Loss: 0.6429, Val Accuracy: 70.10%\n",
      "\n",
      "[18/50] Train Loss: 0.6486, Val Loss: 0.6295, Val Accuracy: 71.28%\n",
      "\n",
      "[19/50] Train Loss: 0.6332, Val Loss: 0.6167, Val Accuracy: 71.79%\n",
      "\n",
      "[20/50] Train Loss: 0.6230, Val Loss: 0.6049, Val Accuracy: 72.13%\n",
      "\n",
      "[21/50] Train Loss: 0.6146, Val Loss: 0.5937, Val Accuracy: 72.64%\n",
      "\n",
      "[22/50] Train Loss: 0.6010, Val Loss: 0.5833, Val Accuracy: 73.48%\n",
      "\n",
      "[23/50] Train Loss: 0.5918, Val Loss: 0.5737, Val Accuracy: 73.82%\n",
      "\n",
      "[24/50] Train Loss: 0.5831, Val Loss: 0.5648, Val Accuracy: 74.66%\n",
      "\n",
      "[25/50] Train Loss: 0.5732, Val Loss: 0.5565, Val Accuracy: 75.17%\n",
      "\n",
      "[26/50] Train Loss: 0.5646, Val Loss: 0.5489, Val Accuracy: 75.84%\n",
      "\n",
      "[27/50] Train Loss: 0.5563, Val Loss: 0.5419, Val Accuracy: 76.01%\n",
      "\n",
      "[28/50] Train Loss: 0.5508, Val Loss: 0.5356, Val Accuracy: 76.86%\n",
      "\n",
      "[29/50] Train Loss: 0.5454, Val Loss: 0.5298, Val Accuracy: 77.70%\n",
      "\n",
      "[30/50] Train Loss: 0.5454, Val Loss: 0.5298, Val Accuracy: 77.70%\n",
      "\n",
      "[31/50] Train Loss: 0.5454, Val Loss: 0.5298, Val Accuracy: 77.70%\n",
      "\n",
      "[32/50] Train Loss: 0.5296, Val Loss: 0.5154, Val Accuracy: 78.04%\n",
      "\n",
      "[33/50] Train Loss: 0.5296, Val Loss: 0.5154, Val Accuracy: 78.04%\n",
      "\n",
      "[34/50] Train Loss: 0.5222, Val Loss: 0.5081, Val Accuracy: 78.21%\n",
      "\n",
      "[35/50] Train Loss: 0.5179, Val Loss: 0.5051, Val Accuracy: 78.38%\n",
      "\n",
      "[36/50] Train Loss: 0.5179, Val Loss: 0.5051, Val Accuracy: 78.38%\n",
      "\n",
      "[37/50] Train Loss: 0.5131, Val Loss: 0.5015, Val Accuracy: 78.55%\n",
      "\n",
      "[38/50] Train Loss: 0.5123, Val Loss: 0.4994, Val Accuracy: 78.72%\n",
      "\n",
      "[39/50] Train Loss: 0.5123, Val Loss: 0.4994, Val Accuracy: 78.72%\n",
      "\n",
      "[40/50] Train Loss: 0.5075, Val Loss: 0.4961, Val Accuracy: 78.89%\n",
      "\n",
      "[41/50] Train Loss: 0.5075, Val Loss: 0.4961, Val Accuracy: 78.89%\n",
      "\n",
      "[42/50] Train Loss: 0.5074, Val Loss: 0.4940, Val Accuracy: 79.22%\n",
      "\n",
      "[43/50] Train Loss: 0.5074, Val Loss: 0.4940, Val Accuracy: 79.22%\n",
      "\n",
      "[44/50] Train Loss: 0.5074, Val Loss: 0.4940, Val Accuracy: 79.22%\n",
      "\n",
      "[45/50] Train Loss: 0.5074, Val Loss: 0.4940, Val Accuracy: 79.22%\n",
      "\n",
      "[46/50] Train Loss: 0.5074, Val Loss: 0.4940, Val Accuracy: 79.22%\n",
      "\n",
      "[47/50] Train Loss: 0.5074, Val Loss: 0.4940, Val Accuracy: 79.22%\n",
      "\n",
      "[48/50] Train Loss: 0.5074, Val Loss: 0.4940, Val Accuracy: 79.22%\n",
      "\n",
      "[49/50] Train Loss: 0.5074, Val Loss: 0.4940, Val Accuracy: 79.22%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       201        |          92         |\n",
      "| true nonlenses |        33        |         267         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 78.9207% |\n",
      "|    loss   |  0.0276  |\n",
      "| auc score |  0.8389  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8590  | 0.6860 |  0.7628 |   293   |\n",
      "|   nonlenses    |   0.7437  | 0.8900 |  0.8103 |   300   |\n",
      "| macro averaged |   0.8014  | 0.7880 |  0.7866 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 17\n",
      "lr: 0.0001, momentum: 0.9, weight_decay: 0.0005, num_epochs: 50\n",
      "\n",
      "[0/50] Train Loss: 0.3759, Val Loss: 0.3121, Val Accuracy: 88.18%\n",
      "\n",
      "[1/50] Train Loss: 0.3759, Val Loss: 0.3121, Val Accuracy: 88.18%\n",
      "\n",
      "[2/50] Train Loss: 0.3759, Val Loss: 0.3121, Val Accuracy: 88.18%\n",
      "\n",
      "[3/50] Train Loss: 0.2326, Val Loss: 0.2612, Val Accuracy: 88.85%\n",
      "\n",
      "[4/50] Train Loss: 0.2326, Val Loss: 0.2612, Val Accuracy: 88.85%\n",
      "\n",
      "[5/50] Train Loss: 0.1971, Val Loss: 0.2462, Val Accuracy: 90.20%\n",
      "\n",
      "[6/50] Train Loss: 0.1819, Val Loss: 0.2353, Val Accuracy: 90.37%\n",
      "\n",
      "[7/50] Train Loss: 0.1819, Val Loss: 0.2353, Val Accuracy: 90.37%\n",
      "\n",
      "[8/50] Train Loss: 0.1819, Val Loss: 0.2353, Val Accuracy: 90.37%\n",
      "\n",
      "[9/50] Train Loss: 0.1819, Val Loss: 0.2353, Val Accuracy: 90.37%\n",
      "\n",
      "[10/50] Train Loss: 0.1819, Val Loss: 0.2353, Val Accuracy: 90.37%\n",
      "\n",
      "[11/50] Train Loss: 0.1819, Val Loss: 0.2353, Val Accuracy: 90.37%\n",
      "\n",
      "[12/50] Train Loss: 0.1819, Val Loss: 0.2353, Val Accuracy: 90.37%\n",
      "\n",
      "[13/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[14/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[15/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[16/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[17/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[18/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[19/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[20/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[21/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[22/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[23/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[24/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[25/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[26/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[27/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[28/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[29/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[30/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[31/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[32/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[33/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[34/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[35/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[36/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[37/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[38/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[39/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[40/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[41/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[42/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[43/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[44/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[45/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[46/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[47/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[48/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "[49/50] Train Loss: 0.1307, Val Loss: 0.2933, Val Accuracy: 91.55%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       264        |          29         |\n",
      "| true nonlenses |        32        |         268         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 89.7133% |\n",
      "|    loss   |  0.0018  |\n",
      "| auc score |  0.9465  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8919  | 0.9010 |  0.8964 |   293   |\n",
      "|   nonlenses    |   0.9024  | 0.8933 |  0.8978 |   300   |\n",
      "| macro averaged |   0.8971  | 0.8972 |  0.8971 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 18\n",
      "lr: 1e-05, momentum: 0.9, weight_decay: 0.0005, num_epochs: 50\n",
      "\n",
      "[0/50] Train Loss: 0.4470, Val Loss: 0.3404, Val Accuracy: 86.82%\n",
      "\n",
      "[1/50] Train Loss: 0.3281, Val Loss: 0.3073, Val Accuracy: 86.99%\n",
      "\n",
      "[2/50] Train Loss: 0.2907, Val Loss: 0.2874, Val Accuracy: 88.68%\n",
      "\n",
      "[3/50] Train Loss: 0.2588, Val Loss: 0.2483, Val Accuracy: 89.86%\n",
      "\n",
      "[4/50] Train Loss: 0.2367, Val Loss: 0.2553, Val Accuracy: 90.37%\n",
      "\n",
      "[5/50] Train Loss: 0.2367, Val Loss: 0.2553, Val Accuracy: 90.37%\n",
      "\n",
      "[6/50] Train Loss: 0.2367, Val Loss: 0.2553, Val Accuracy: 90.37%\n",
      "\n",
      "[7/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[8/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[9/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[10/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[11/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[12/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[13/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[14/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[15/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[16/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[17/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[18/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[19/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[20/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[21/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[22/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[23/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[24/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[25/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[26/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[27/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[28/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[29/50] Train Loss: 0.1671, Val Loss: 0.2395, Val Accuracy: 90.71%\n",
      "\n",
      "[30/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[31/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[32/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[33/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[34/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[35/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[36/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[37/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[38/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[39/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[40/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[41/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[42/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[43/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[44/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[45/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[46/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[47/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[48/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "[49/50] Train Loss: 0.0079, Val Loss: 0.5045, Val Accuracy: 90.88%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       270        |          23         |\n",
      "| true nonlenses |        37        |         263         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 89.8820% |\n",
      "|    loss   |  0.0000  |\n",
      "| auc score |  0.9589  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8795  | 0.9215 |  0.9000 |   293   |\n",
      "|   nonlenses    |   0.9196  | 0.8767 |  0.8976 |   300   |\n",
      "| macro averaged |   0.8995  | 0.8991 |  0.8988 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "\n",
      "\n",
      "================================================================================================\n",
      "Iter 19\n",
      "lr: 1e-06, momentum: 0.9, weight_decay: 0.0005, num_epochs: 50\n",
      "\n",
      "[0/50] Train Loss: 0.5283, Val Loss: 0.4540, Val Accuracy: 82.60%\n",
      "\n",
      "[1/50] Train Loss: 0.4656, Val Loss: 0.4215, Val Accuracy: 84.63%\n",
      "\n",
      "[2/50] Train Loss: 0.4656, Val Loss: 0.4215, Val Accuracy: 84.63%\n",
      "\n",
      "[3/50] Train Loss: 0.4108, Val Loss: 0.3947, Val Accuracy: 84.80%\n",
      "\n",
      "[4/50] Train Loss: 0.4108, Val Loss: 0.3947, Val Accuracy: 84.80%\n",
      "\n",
      "[5/50] Train Loss: 0.3849, Val Loss: 0.3771, Val Accuracy: 84.97%\n",
      "\n",
      "[6/50] Train Loss: 0.3754, Val Loss: 0.3685, Val Accuracy: 85.14%\n",
      "\n",
      "[7/50] Train Loss: 0.3646, Val Loss: 0.3617, Val Accuracy: 85.30%\n",
      "\n",
      "[8/50] Train Loss: 0.3646, Val Loss: 0.3617, Val Accuracy: 85.30%\n",
      "\n",
      "[9/50] Train Loss: 0.3489, Val Loss: 0.3469, Val Accuracy: 85.64%\n",
      "\n",
      "[10/50] Train Loss: 0.3385, Val Loss: 0.3409, Val Accuracy: 85.98%\n",
      "\n",
      "[11/50] Train Loss: 0.3331, Val Loss: 0.3319, Val Accuracy: 86.49%\n",
      "\n",
      "[12/50] Train Loss: 0.3331, Val Loss: 0.3319, Val Accuracy: 86.49%\n",
      "\n",
      "[13/50] Train Loss: 0.3331, Val Loss: 0.3319, Val Accuracy: 86.49%\n",
      "\n",
      "[14/50] Train Loss: 0.3331, Val Loss: 0.3319, Val Accuracy: 86.49%\n",
      "\n",
      "[15/50] Train Loss: 0.3063, Val Loss: 0.3054, Val Accuracy: 86.66%\n",
      "\n",
      "[16/50] Train Loss: 0.2994, Val Loss: 0.3000, Val Accuracy: 86.82%\n",
      "\n",
      "[17/50] Train Loss: 0.2974, Val Loss: 0.2934, Val Accuracy: 87.33%\n",
      "\n",
      "[18/50] Train Loss: 0.2974, Val Loss: 0.2934, Val Accuracy: 87.33%\n",
      "\n",
      "[19/50] Train Loss: 0.2974, Val Loss: 0.2934, Val Accuracy: 87.33%\n",
      "\n",
      "[20/50] Train Loss: 0.2823, Val Loss: 0.2829, Val Accuracy: 88.01%\n",
      "\n",
      "[21/50] Train Loss: 0.2823, Val Loss: 0.2829, Val Accuracy: 88.01%\n",
      "\n",
      "[22/50] Train Loss: 0.2795, Val Loss: 0.2783, Val Accuracy: 88.18%\n",
      "\n",
      "[23/50] Train Loss: 0.2723, Val Loss: 0.2764, Val Accuracy: 88.34%\n",
      "\n",
      "[24/50] Train Loss: 0.2742, Val Loss: 0.2747, Val Accuracy: 88.51%\n",
      "\n",
      "[25/50] Train Loss: 0.2742, Val Loss: 0.2747, Val Accuracy: 88.51%\n",
      "\n",
      "[26/50] Train Loss: 0.2742, Val Loss: 0.2747, Val Accuracy: 88.51%\n",
      "\n",
      "[27/50] Train Loss: 0.2602, Val Loss: 0.2703, Val Accuracy: 88.68%\n",
      "\n",
      "[28/50] Train Loss: 0.2602, Val Loss: 0.2703, Val Accuracy: 88.68%\n",
      "\n",
      "[29/50] Train Loss: 0.2602, Val Loss: 0.2703, Val Accuracy: 88.68%\n",
      "\n",
      "[30/50] Train Loss: 0.2602, Val Loss: 0.2703, Val Accuracy: 88.68%\n",
      "\n",
      "[31/50] Train Loss: 0.2563, Val Loss: 0.2672, Val Accuracy: 88.85%\n",
      "\n",
      "[32/50] Train Loss: 0.2563, Val Loss: 0.2672, Val Accuracy: 88.85%\n",
      "\n",
      "[33/50] Train Loss: 0.2563, Val Loss: 0.2672, Val Accuracy: 88.85%\n",
      "\n",
      "[34/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[35/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[36/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[37/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[38/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[39/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[40/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[41/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[42/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[43/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[44/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[45/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[46/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[47/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[48/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "[49/50] Train Loss: 0.2526, Val Loss: 0.2651, Val Accuracy: 89.19%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       247        |          46         |\n",
      "| true nonlenses |        37        |         263         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 86.0034% |\n",
      "|    loss   |  0.0080  |\n",
      "| auc score |  0.9481  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8697  | 0.8430 |  0.8562 |   293   |\n",
      "|   nonlenses    |   0.8511  | 0.8767 |  0.8637 |   300   |\n",
      "| macro averaged |   0.8604  | 0.8598 |  0.8599 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 20\n",
      "lr: 1e-07, momentum: 0.9, weight_decay: 0.0005, num_epochs: 50\n",
      "\n",
      "[0/50] Train Loss: 0.9477, Val Loss: 0.9102, Val Accuracy: 40.37%\n",
      "\n",
      "[1/50] Train Loss: 0.9110, Val Loss: 0.8723, Val Accuracy: 43.58%\n",
      "\n",
      "[2/50] Train Loss: 0.8772, Val Loss: 0.8383, Val Accuracy: 46.96%\n",
      "\n",
      "[3/50] Train Loss: 0.8478, Val Loss: 0.8084, Val Accuracy: 49.66%\n",
      "\n",
      "[4/50] Train Loss: 0.8234, Val Loss: 0.7853, Val Accuracy: 51.86%\n",
      "\n",
      "[5/50] Train Loss: 0.8011, Val Loss: 0.7639, Val Accuracy: 53.21%\n",
      "\n",
      "[6/50] Train Loss: 0.7832, Val Loss: 0.7441, Val Accuracy: 54.73%\n",
      "\n",
      "[7/50] Train Loss: 0.7657, Val Loss: 0.7258, Val Accuracy: 55.24%\n",
      "\n",
      "[8/50] Train Loss: 0.7480, Val Loss: 0.7088, Val Accuracy: 56.42%\n",
      "\n",
      "[9/50] Train Loss: 0.7326, Val Loss: 0.6931, Val Accuracy: 57.60%\n",
      "\n",
      "[10/50] Train Loss: 0.7193, Val Loss: 0.6788, Val Accuracy: 58.61%\n",
      "\n",
      "[11/50] Train Loss: 0.7053, Val Loss: 0.6650, Val Accuracy: 60.64%\n",
      "\n",
      "[12/50] Train Loss: 0.6930, Val Loss: 0.6523, Val Accuracy: 62.33%\n",
      "\n",
      "[13/50] Train Loss: 0.6816, Val Loss: 0.6405, Val Accuracy: 63.51%\n",
      "\n",
      "[14/50] Train Loss: 0.6686, Val Loss: 0.6295, Val Accuracy: 65.03%\n",
      "\n",
      "[15/50] Train Loss: 0.6591, Val Loss: 0.6192, Val Accuracy: 67.06%\n",
      "\n",
      "[16/50] Train Loss: 0.6498, Val Loss: 0.6095, Val Accuracy: 68.41%\n",
      "\n",
      "[17/50] Train Loss: 0.6396, Val Loss: 0.6006, Val Accuracy: 70.10%\n",
      "\n",
      "[18/50] Train Loss: 0.6303, Val Loss: 0.5922, Val Accuracy: 71.45%\n",
      "\n",
      "[19/50] Train Loss: 0.6221, Val Loss: 0.5843, Val Accuracy: 71.79%\n",
      "\n",
      "[20/50] Train Loss: 0.6221, Val Loss: 0.5843, Val Accuracy: 71.79%\n",
      "\n",
      "[21/50] Train Loss: 0.6071, Val Loss: 0.5708, Val Accuracy: 72.80%\n",
      "\n",
      "[22/50] Train Loss: 0.6003, Val Loss: 0.5642, Val Accuracy: 73.82%\n",
      "\n",
      "[23/50] Train Loss: 0.5958, Val Loss: 0.5582, Val Accuracy: 74.49%\n",
      "\n",
      "[24/50] Train Loss: 0.5904, Val Loss: 0.5525, Val Accuracy: 74.66%\n",
      "\n",
      "[25/50] Train Loss: 0.5827, Val Loss: 0.5470, Val Accuracy: 75.17%\n",
      "\n",
      "[26/50] Train Loss: 0.5809, Val Loss: 0.5420, Val Accuracy: 75.68%\n",
      "\n",
      "[27/50] Train Loss: 0.5809, Val Loss: 0.5420, Val Accuracy: 75.68%\n",
      "\n",
      "[28/50] Train Loss: 0.5703, Val Loss: 0.5335, Val Accuracy: 76.35%\n",
      "\n",
      "[29/50] Train Loss: 0.5653, Val Loss: 0.5297, Val Accuracy: 76.69%\n",
      "\n",
      "[30/50] Train Loss: 0.5653, Val Loss: 0.5297, Val Accuracy: 76.69%\n",
      "\n",
      "[31/50] Train Loss: 0.5582, Val Loss: 0.5235, Val Accuracy: 76.86%\n",
      "\n",
      "[32/50] Train Loss: 0.5558, Val Loss: 0.5210, Val Accuracy: 77.53%\n",
      "\n",
      "[33/50] Train Loss: 0.5533, Val Loss: 0.5188, Val Accuracy: 78.38%\n",
      "\n",
      "[34/50] Train Loss: 0.5533, Val Loss: 0.5188, Val Accuracy: 78.38%\n",
      "\n",
      "[35/50] Train Loss: 0.5479, Val Loss: 0.5149, Val Accuracy: 78.72%\n",
      "\n",
      "[36/50] Train Loss: 0.5479, Val Loss: 0.5149, Val Accuracy: 78.72%\n",
      "\n",
      "[37/50] Train Loss: 0.5479, Val Loss: 0.5149, Val Accuracy: 78.72%\n",
      "\n",
      "[38/50] Train Loss: 0.5447, Val Loss: 0.5107, Val Accuracy: 78.89%\n",
      "\n",
      "[39/50] Train Loss: 0.5435, Val Loss: 0.5097, Val Accuracy: 79.05%\n",
      "\n",
      "[40/50] Train Loss: 0.5434, Val Loss: 0.5088, Val Accuracy: 79.22%\n",
      "\n",
      "[41/50] Train Loss: 0.5409, Val Loss: 0.5081, Val Accuracy: 79.39%\n",
      "\n",
      "[42/50] Train Loss: 0.5409, Val Loss: 0.5081, Val Accuracy: 79.39%\n",
      "\n",
      "[43/50] Train Loss: 0.5409, Val Loss: 0.5081, Val Accuracy: 79.39%\n",
      "\n",
      "[44/50] Train Loss: 0.5409, Val Loss: 0.5081, Val Accuracy: 79.39%\n",
      "\n",
      "[45/50] Train Loss: 0.5409, Val Loss: 0.5081, Val Accuracy: 79.39%\n",
      "\n",
      "[46/50] Train Loss: 0.5409, Val Loss: 0.5081, Val Accuracy: 79.39%\n",
      "\n",
      "[47/50] Train Loss: 0.5409, Val Loss: 0.5081, Val Accuracy: 79.39%\n",
      "\n",
      "[48/50] Train Loss: 0.5409, Val Loss: 0.5081, Val Accuracy: 79.39%\n",
      "\n",
      "[49/50] Train Loss: 0.5409, Val Loss: 0.5081, Val Accuracy: 79.39%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       200        |          93         |\n",
      "| true nonlenses |        52        |         248         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 75.5481% |\n",
      "|    loss   |  0.0259  |\n",
      "| auc score |  0.8283  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.7937  | 0.6826 |  0.7339 |   293   |\n",
      "|   nonlenses    |   0.7273  | 0.8267 |  0.7738 |   300   |\n",
      "| macro averaged |   0.7605  | 0.7546 |  0.7539 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 21\n",
      "lr: 0.0001, momentum: 0.9, weight_decay: 5e-05, num_epochs: 50\n",
      "\n",
      "[0/50] Train Loss: 0.3530, Val Loss: 0.2956, Val Accuracy: 87.84%\n",
      "\n",
      "[1/50] Train Loss: 0.3530, Val Loss: 0.2956, Val Accuracy: 87.84%\n",
      "\n",
      "[2/50] Train Loss: 0.2411, Val Loss: 0.2652, Val Accuracy: 89.53%\n",
      "\n",
      "[3/50] Train Loss: 0.2411, Val Loss: 0.2652, Val Accuracy: 89.53%\n",
      "\n",
      "[4/50] Train Loss: 0.2411, Val Loss: 0.2652, Val Accuracy: 89.53%\n",
      "\n",
      "[5/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[6/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[7/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[8/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[9/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[10/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[11/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[12/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[13/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[14/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[15/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[16/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[17/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[18/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[19/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[20/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[21/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[22/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[23/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[24/50] Train Loss: 0.1991, Val Loss: 0.2352, Val Accuracy: 90.71%\n",
      "\n",
      "[25/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[26/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[27/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[28/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[29/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[30/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[31/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[32/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[33/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[34/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[35/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[36/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[37/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[38/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[39/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[40/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[41/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[42/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[43/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[44/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[45/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[46/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[47/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[48/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "[49/50] Train Loss: 0.0067, Val Loss: 0.5649, Val Accuracy: 90.88%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       267        |          26         |\n",
      "| true nonlenses |        40        |         260         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 88.8702% |\n",
      "|    loss   |  0.0028  |\n",
      "| auc score |  0.9400  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8697  | 0.9113 |  0.8900 |   293   |\n",
      "|   nonlenses    |   0.9091  | 0.8667 |  0.8874 |   300   |\n",
      "| macro averaged |   0.8894  | 0.8890 |  0.8887 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 22\n",
      "lr: 1e-05, momentum: 0.9, weight_decay: 5e-05, num_epochs: 50\n",
      "\n",
      "[0/50] Train Loss: 0.5142, Val Loss: 0.3602, Val Accuracy: 85.47%\n",
      "\n",
      "[1/50] Train Loss: 0.3532, Val Loss: 0.3142, Val Accuracy: 87.84%\n",
      "\n",
      "[2/50] Train Loss: 0.3532, Val Loss: 0.3142, Val Accuracy: 87.84%\n",
      "\n",
      "[3/50] Train Loss: 0.2616, Val Loss: 0.2743, Val Accuracy: 88.68%\n",
      "\n",
      "[4/50] Train Loss: 0.2229, Val Loss: 0.2450, Val Accuracy: 89.70%\n",
      "\n",
      "[5/50] Train Loss: 0.2229, Val Loss: 0.2450, Val Accuracy: 89.70%\n",
      "\n",
      "[6/50] Train Loss: 0.2229, Val Loss: 0.2450, Val Accuracy: 89.70%\n",
      "\n",
      "[7/50] Train Loss: 0.2229, Val Loss: 0.2450, Val Accuracy: 89.70%\n",
      "\n",
      "[8/50] Train Loss: 0.1329, Val Loss: 0.2614, Val Accuracy: 89.86%\n",
      "\n",
      "[9/50] Train Loss: 0.1329, Val Loss: 0.2614, Val Accuracy: 89.86%\n",
      "\n",
      "[10/50] Train Loss: 0.1329, Val Loss: 0.2614, Val Accuracy: 89.86%\n",
      "\n",
      "[11/50] Train Loss: 0.1329, Val Loss: 0.2614, Val Accuracy: 89.86%\n",
      "\n",
      "[12/50] Train Loss: 0.1329, Val Loss: 0.2614, Val Accuracy: 89.86%\n",
      "\n",
      "[13/50] Train Loss: 0.1329, Val Loss: 0.2614, Val Accuracy: 89.86%\n",
      "\n",
      "[14/50] Train Loss: 0.1329, Val Loss: 0.2614, Val Accuracy: 89.86%\n",
      "\n",
      "[15/50] Train Loss: 0.1329, Val Loss: 0.2614, Val Accuracy: 89.86%\n",
      "\n",
      "[16/50] Train Loss: 0.1329, Val Loss: 0.2614, Val Accuracy: 89.86%\n",
      "\n",
      "[17/50] Train Loss: 0.1329, Val Loss: 0.2614, Val Accuracy: 89.86%\n",
      "\n",
      "[18/50] Train Loss: 0.1329, Val Loss: 0.2614, Val Accuracy: 89.86%\n",
      "\n",
      "[19/50] Train Loss: 0.1329, Val Loss: 0.2614, Val Accuracy: 89.86%\n",
      "\n",
      "[20/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[21/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[22/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[23/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[24/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[25/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[26/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[27/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[28/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[29/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[30/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[31/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[32/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[33/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[34/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[35/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[36/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[37/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[38/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[39/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[40/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[41/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[42/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[43/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[44/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[45/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[46/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[47/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[48/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "[49/50] Train Loss: 0.0197, Val Loss: 0.4575, Val Accuracy: 91.22%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       260        |          33         |\n",
      "| true nonlenses |        35        |         265         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 88.5329% |\n",
      "|    loss   |  0.0173  |\n",
      "| auc score |  0.9562  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8814  | 0.8874 |  0.8844 |   293   |\n",
      "|   nonlenses    |   0.8893  | 0.8833 |  0.8863 |   300   |\n",
      "| macro averaged |   0.8853  | 0.8854 |  0.8853 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 23\n",
      "lr: 1e-06, momentum: 0.9, weight_decay: 5e-05, num_epochs: 50\n",
      "\n",
      "[0/50] Train Loss: 0.7519, Val Loss: 0.5790, Val Accuracy: 69.93%\n",
      "\n",
      "[1/50] Train Loss: 0.5738, Val Loss: 0.4944, Val Accuracy: 76.35%\n",
      "\n",
      "[2/50] Train Loss: 0.5035, Val Loss: 0.4444, Val Accuracy: 81.76%\n",
      "\n",
      "[3/50] Train Loss: 0.4594, Val Loss: 0.4121, Val Accuracy: 83.78%\n",
      "\n",
      "[4/50] Train Loss: 0.4314, Val Loss: 0.3969, Val Accuracy: 84.46%\n",
      "\n",
      "[5/50] Train Loss: 0.4053, Val Loss: 0.3834, Val Accuracy: 85.14%\n",
      "\n",
      "[6/50] Train Loss: 0.3872, Val Loss: 0.3712, Val Accuracy: 85.64%\n",
      "\n",
      "[7/50] Train Loss: 0.3872, Val Loss: 0.3712, Val Accuracy: 85.64%\n",
      "\n",
      "[8/50] Train Loss: 0.3872, Val Loss: 0.3712, Val Accuracy: 85.64%\n",
      "\n",
      "[9/50] Train Loss: 0.3872, Val Loss: 0.3712, Val Accuracy: 85.64%\n",
      "\n",
      "[10/50] Train Loss: 0.3872, Val Loss: 0.3712, Val Accuracy: 85.64%\n",
      "\n",
      "[11/50] Train Loss: 0.3389, Val Loss: 0.3382, Val Accuracy: 86.15%\n",
      "\n",
      "[12/50] Train Loss: 0.3322, Val Loss: 0.3311, Val Accuracy: 86.32%\n",
      "\n",
      "[13/50] Train Loss: 0.3322, Val Loss: 0.3311, Val Accuracy: 86.32%\n",
      "\n",
      "[14/50] Train Loss: 0.3235, Val Loss: 0.3195, Val Accuracy: 86.99%\n",
      "\n",
      "[15/50] Train Loss: 0.3175, Val Loss: 0.3195, Val Accuracy: 87.50%\n",
      "\n",
      "[16/50] Train Loss: 0.3156, Val Loss: 0.3151, Val Accuracy: 88.01%\n",
      "\n",
      "[17/50] Train Loss: 0.3123, Val Loss: 0.3102, Val Accuracy: 88.18%\n",
      "\n",
      "[18/50] Train Loss: 0.3123, Val Loss: 0.3102, Val Accuracy: 88.18%\n",
      "\n",
      "[19/50] Train Loss: 0.3034, Val Loss: 0.3002, Val Accuracy: 88.68%\n",
      "\n",
      "[20/50] Train Loss: 0.3034, Val Loss: 0.3002, Val Accuracy: 88.68%\n",
      "\n",
      "[21/50] Train Loss: 0.3034, Val Loss: 0.3002, Val Accuracy: 88.68%\n",
      "\n",
      "[22/50] Train Loss: 0.3034, Val Loss: 0.3002, Val Accuracy: 88.68%\n",
      "\n",
      "[23/50] Train Loss: 0.2895, Val Loss: 0.2948, Val Accuracy: 88.85%\n",
      "\n",
      "[24/50] Train Loss: 0.2925, Val Loss: 0.2908, Val Accuracy: 89.02%\n",
      "\n",
      "[25/50] Train Loss: 0.2925, Val Loss: 0.2908, Val Accuracy: 89.02%\n",
      "\n",
      "[26/50] Train Loss: 0.2809, Val Loss: 0.2876, Val Accuracy: 89.19%\n",
      "\n",
      "[27/50] Train Loss: 0.2809, Val Loss: 0.2876, Val Accuracy: 89.19%\n",
      "\n",
      "[28/50] Train Loss: 0.2809, Val Loss: 0.2876, Val Accuracy: 89.19%\n",
      "\n",
      "[29/50] Train Loss: 0.2766, Val Loss: 0.2845, Val Accuracy: 89.53%\n",
      "\n",
      "[30/50] Train Loss: 0.2766, Val Loss: 0.2845, Val Accuracy: 89.53%\n",
      "\n",
      "[31/50] Train Loss: 0.2766, Val Loss: 0.2845, Val Accuracy: 89.53%\n",
      "\n",
      "[32/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[33/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[34/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[35/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[36/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[37/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[38/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[39/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[40/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[41/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[42/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[43/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[44/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[45/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[46/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[47/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[48/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "[49/50] Train Loss: 0.2723, Val Loss: 0.2793, Val Accuracy: 89.86%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       253        |          40         |\n",
      "| true nonlenses |        36        |         264         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 87.1838% |\n",
      "|    loss   |  0.0084  |\n",
      "| auc score |  0.9520  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8754  | 0.8635 |  0.8694 |   293   |\n",
      "|   nonlenses    |   0.8684  | 0.8800 |  0.8742 |   300   |\n",
      "| macro averaged |   0.8719  | 0.8717 |  0.8718 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 24\n",
      "lr: 1e-07, momentum: 0.9, weight_decay: 5e-05, num_epochs: 50\n",
      "\n",
      "[0/50] Train Loss: 0.7765, Val Loss: 0.7229, Val Accuracy: 59.63%\n",
      "\n",
      "[1/50] Train Loss: 0.7519, Val Loss: 0.6955, Val Accuracy: 61.15%\n",
      "\n",
      "[2/50] Train Loss: 0.7266, Val Loss: 0.6713, Val Accuracy: 62.16%\n",
      "\n",
      "[3/50] Train Loss: 0.6997, Val Loss: 0.6494, Val Accuracy: 62.67%\n",
      "\n",
      "[4/50] Train Loss: 0.6816, Val Loss: 0.6293, Val Accuracy: 64.53%\n",
      "\n",
      "[5/50] Train Loss: 0.6606, Val Loss: 0.6119, Val Accuracy: 66.22%\n",
      "\n",
      "[6/50] Train Loss: 0.6462, Val Loss: 0.5954, Val Accuracy: 68.75%\n",
      "\n",
      "[7/50] Train Loss: 0.6297, Val Loss: 0.5803, Val Accuracy: 70.27%\n",
      "\n",
      "[8/50] Train Loss: 0.6159, Val Loss: 0.5668, Val Accuracy: 71.79%\n",
      "\n",
      "[9/50] Train Loss: 0.5996, Val Loss: 0.5543, Val Accuracy: 72.13%\n",
      "\n",
      "[10/50] Train Loss: 0.5897, Val Loss: 0.5430, Val Accuracy: 73.99%\n",
      "\n",
      "[11/50] Train Loss: 0.5770, Val Loss: 0.5325, Val Accuracy: 75.17%\n",
      "\n",
      "[12/50] Train Loss: 0.5679, Val Loss: 0.5228, Val Accuracy: 76.35%\n",
      "\n",
      "[13/50] Train Loss: 0.5587, Val Loss: 0.5147, Val Accuracy: 77.20%\n",
      "\n",
      "[14/50] Train Loss: 0.5494, Val Loss: 0.5081, Val Accuracy: 77.87%\n",
      "\n",
      "[15/50] Train Loss: 0.5418, Val Loss: 0.5012, Val Accuracy: 78.04%\n",
      "\n",
      "[16/50] Train Loss: 0.5348, Val Loss: 0.4943, Val Accuracy: 78.21%\n",
      "\n",
      "[17/50] Train Loss: 0.5277, Val Loss: 0.4882, Val Accuracy: 78.89%\n",
      "\n",
      "[18/50] Train Loss: 0.5214, Val Loss: 0.4826, Val Accuracy: 79.05%\n",
      "\n",
      "[19/50] Train Loss: 0.5168, Val Loss: 0.4772, Val Accuracy: 80.07%\n",
      "\n",
      "[20/50] Train Loss: 0.5110, Val Loss: 0.4725, Val Accuracy: 80.57%\n",
      "\n",
      "[21/50] Train Loss: 0.5066, Val Loss: 0.4682, Val Accuracy: 81.42%\n",
      "\n",
      "[22/50] Train Loss: 0.5009, Val Loss: 0.4644, Val Accuracy: 81.93%\n",
      "\n",
      "[23/50] Train Loss: 0.4990, Val Loss: 0.4607, Val Accuracy: 82.43%\n",
      "\n",
      "[24/50] Train Loss: 0.4990, Val Loss: 0.4607, Val Accuracy: 82.43%\n",
      "\n",
      "[25/50] Train Loss: 0.4990, Val Loss: 0.4607, Val Accuracy: 82.43%\n",
      "\n",
      "[26/50] Train Loss: 0.4990, Val Loss: 0.4607, Val Accuracy: 82.43%\n",
      "\n",
      "[27/50] Train Loss: 0.4990, Val Loss: 0.4607, Val Accuracy: 82.43%\n",
      "\n",
      "[28/50] Train Loss: 0.4990, Val Loss: 0.4607, Val Accuracy: 82.43%\n",
      "\n",
      "[29/50] Train Loss: 0.4787, Val Loss: 0.4443, Val Accuracy: 82.60%\n",
      "\n",
      "[30/50] Train Loss: 0.4787, Val Loss: 0.4443, Val Accuracy: 82.60%\n",
      "\n",
      "[31/50] Train Loss: 0.4787, Val Loss: 0.4443, Val Accuracy: 82.60%\n",
      "\n",
      "[32/50] Train Loss: 0.4787, Val Loss: 0.4443, Val Accuracy: 82.60%\n",
      "\n",
      "[33/50] Train Loss: 0.4787, Val Loss: 0.4443, Val Accuracy: 82.60%\n",
      "\n",
      "[34/50] Train Loss: 0.4686, Val Loss: 0.4366, Val Accuracy: 82.77%\n",
      "\n",
      "[35/50] Train Loss: 0.4686, Val Loss: 0.4366, Val Accuracy: 82.77%\n",
      "\n",
      "[36/50] Train Loss: 0.4686, Val Loss: 0.4366, Val Accuracy: 82.77%\n",
      "\n",
      "[37/50] Train Loss: 0.4686, Val Loss: 0.4366, Val Accuracy: 82.77%\n",
      "\n",
      "[38/50] Train Loss: 0.4686, Val Loss: 0.4366, Val Accuracy: 82.77%\n",
      "\n",
      "[39/50] Train Loss: 0.4615, Val Loss: 0.4325, Val Accuracy: 82.94%\n",
      "\n",
      "[40/50] Train Loss: 0.4615, Val Loss: 0.4325, Val Accuracy: 82.94%\n",
      "\n",
      "[41/50] Train Loss: 0.4615, Val Loss: 0.4325, Val Accuracy: 82.94%\n",
      "\n",
      "[42/50] Train Loss: 0.4624, Val Loss: 0.4313, Val Accuracy: 83.11%\n",
      "\n",
      "[43/50] Train Loss: 0.4624, Val Loss: 0.4313, Val Accuracy: 83.11%\n",
      "\n",
      "[44/50] Train Loss: 0.4624, Val Loss: 0.4313, Val Accuracy: 83.11%\n",
      "\n",
      "[45/50] Train Loss: 0.4624, Val Loss: 0.4313, Val Accuracy: 83.11%\n",
      "\n",
      "[46/50] Train Loss: 0.4624, Val Loss: 0.4313, Val Accuracy: 83.11%\n",
      "\n",
      "[47/50] Train Loss: 0.4624, Val Loss: 0.4313, Val Accuracy: 83.11%\n",
      "\n",
      "[48/50] Train Loss: 0.4624, Val Loss: 0.4313, Val Accuracy: 83.11%\n",
      "\n",
      "[49/50] Train Loss: 0.4624, Val Loss: 0.4313, Val Accuracy: 83.11%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       224        |          69         |\n",
      "| true nonlenses |        48        |         252         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 80.2698% |\n",
      "|    loss   |  0.0221  |\n",
      "| auc score |  0.8719  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8235  | 0.7645 |  0.7929 |   293   |\n",
      "|   nonlenses    |   0.7850  | 0.8400 |  0.8116 |   300   |\n",
      "| macro averaged |   0.8043  | 0.8023 |  0.8023 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 25\n",
      "lr: 0.0001, momentum: 0.9, weight_decay: 0.0, num_epochs: 100\n",
      "\n",
      "[0/100] Train Loss: 0.4330, Val Loss: 0.2754, Val Accuracy: 88.68%\n",
      "\n",
      "[1/100] Train Loss: 0.2916, Val Loss: 0.2713, Val Accuracy: 89.02%\n",
      "\n",
      "[2/100] Train Loss: 0.2916, Val Loss: 0.2713, Val Accuracy: 89.02%\n",
      "\n",
      "[3/100] Train Loss: 0.2916, Val Loss: 0.2713, Val Accuracy: 89.02%\n",
      "\n",
      "[4/100] Train Loss: 0.2916, Val Loss: 0.2713, Val Accuracy: 89.02%\n",
      "\n",
      "[5/100] Train Loss: 0.2916, Val Loss: 0.2713, Val Accuracy: 89.02%\n",
      "\n",
      "[6/100] Train Loss: 0.2916, Val Loss: 0.2713, Val Accuracy: 89.02%\n",
      "\n",
      "[7/100] Train Loss: 0.1610, Val Loss: 0.3396, Val Accuracy: 90.54%\n",
      "\n",
      "[8/100] Train Loss: 0.1610, Val Loss: 0.3396, Val Accuracy: 90.54%\n",
      "\n",
      "[9/100] Train Loss: 0.1610, Val Loss: 0.3396, Val Accuracy: 90.54%\n",
      "\n",
      "[10/100] Train Loss: 0.1610, Val Loss: 0.3396, Val Accuracy: 90.54%\n",
      "\n",
      "[11/100] Train Loss: 0.0989, Val Loss: 0.3607, Val Accuracy: 90.71%\n",
      "\n",
      "[12/100] Train Loss: 0.0989, Val Loss: 0.3607, Val Accuracy: 90.71%\n",
      "\n",
      "[13/100] Train Loss: 0.0933, Val Loss: 0.3544, Val Accuracy: 91.22%\n",
      "\n",
      "[14/100] Train Loss: 0.0933, Val Loss: 0.3544, Val Accuracy: 91.22%\n",
      "\n",
      "[15/100] Train Loss: 0.0933, Val Loss: 0.3544, Val Accuracy: 91.22%\n",
      "\n",
      "[16/100] Train Loss: 0.0933, Val Loss: 0.3544, Val Accuracy: 91.22%\n",
      "\n",
      "[17/100] Train Loss: 0.0933, Val Loss: 0.3544, Val Accuracy: 91.22%\n",
      "\n",
      "[18/100] Train Loss: 0.0933, Val Loss: 0.3544, Val Accuracy: 91.22%\n",
      "\n",
      "[19/100] Train Loss: 0.0933, Val Loss: 0.3544, Val Accuracy: 91.22%\n",
      "\n",
      "[20/100] Train Loss: 0.0933, Val Loss: 0.3544, Val Accuracy: 91.22%\n",
      "\n",
      "[21/100] Train Loss: 0.0933, Val Loss: 0.3544, Val Accuracy: 91.22%\n",
      "\n",
      "[22/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[23/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[24/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[25/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[26/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[27/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[28/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[29/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[30/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[31/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[32/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[33/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[34/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[35/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[36/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[37/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[38/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[39/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[40/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[41/100] Train Loss: 0.0430, Val Loss: 0.4333, Val Accuracy: 91.72%\n",
      "\n",
      "[42/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[43/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[44/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[45/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[46/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[47/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[48/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[49/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[50/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[51/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[52/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[53/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[54/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[55/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[56/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[57/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[58/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[59/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[60/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[61/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[62/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[63/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[64/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[65/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[66/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[67/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[68/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[69/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[70/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[71/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[72/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[73/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[74/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[75/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[76/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[77/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[78/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[79/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[80/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[81/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[82/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[83/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[84/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[85/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[86/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[87/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[88/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[89/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[90/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[91/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[92/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[93/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[94/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[95/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[96/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[97/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[98/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "[99/100] Train Loss: 0.0064, Val Loss: 0.5452, Val Accuracy: 91.89%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       267        |          26         |\n",
      "| true nonlenses |        24        |         276         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 91.5683% |\n",
      "|    loss   |  0.0121  |\n",
      "| auc score |  0.9597  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.9175  | 0.9113 |  0.9144 |   293   |\n",
      "|   nonlenses    |   0.9139  | 0.9200 |  0.9169 |   300   |\n",
      "| macro averaged |   0.9157  | 0.9156 |  0.9157 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 26\n",
      "lr: 1e-05, momentum: 0.9, weight_decay: 0.0, num_epochs: 100\n",
      "\n",
      "[0/100] Train Loss: 0.4330, Val Loss: 0.3133, Val Accuracy: 87.67%\n",
      "\n",
      "[1/100] Train Loss: 0.4330, Val Loss: 0.3133, Val Accuracy: 87.67%\n",
      "\n",
      "[2/100] Train Loss: 0.2697, Val Loss: 0.2750, Val Accuracy: 89.19%\n",
      "\n",
      "[3/100] Train Loss: 0.2697, Val Loss: 0.2750, Val Accuracy: 89.19%\n",
      "\n",
      "[4/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[5/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[6/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[7/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[8/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[9/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[10/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[11/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[12/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[13/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[14/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[15/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[16/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[17/100] Train Loss: 0.2130, Val Loss: 0.2508, Val Accuracy: 91.05%\n",
      "\n",
      "[18/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[19/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[20/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[21/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[22/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[23/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[24/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[25/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[26/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[27/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[28/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[29/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[30/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[31/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[32/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[33/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[34/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[35/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[36/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[37/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[38/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[39/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[40/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[41/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[42/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[43/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[44/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[45/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[46/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[47/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[48/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[49/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[50/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[51/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[52/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[53/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[54/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[55/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[56/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[57/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[58/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[59/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[60/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[61/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[62/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[63/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[64/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[65/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[66/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[67/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[68/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[69/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[70/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[71/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[72/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[73/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[74/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[75/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[76/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[77/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[78/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[79/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[80/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[81/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[82/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[83/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[84/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[85/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[86/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[87/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[88/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[89/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[90/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[91/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[92/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[93/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[94/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[95/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[96/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[97/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[98/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "[99/100] Train Loss: 0.0429, Val Loss: 0.4028, Val Accuracy: 91.39%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       243        |          50         |\n",
      "| true nonlenses |        16        |         284         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 88.8702% |\n",
      "|    loss   |  0.0108  |\n",
      "| auc score |  0.9549  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.9382  | 0.8294 |  0.8804 |   293   |\n",
      "|   nonlenses    |   0.8503  | 0.9467 |  0.8959 |   300   |\n",
      "| macro averaged |   0.8943  | 0.8880 |  0.8882 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 27\n",
      "lr: 1e-06, momentum: 0.9, weight_decay: 0.0, num_epochs: 100\n",
      "\n",
      "[0/100] Train Loss: 1.0320, Val Loss: 0.8435, Val Accuracy: 49.16%\n",
      "\n",
      "[1/100] Train Loss: 0.8067, Val Loss: 0.6993, Val Accuracy: 59.29%\n",
      "\n",
      "[2/100] Train Loss: 0.6755, Val Loss: 0.5760, Val Accuracy: 70.78%\n",
      "\n",
      "[3/100] Train Loss: 0.5375, Val Loss: 0.4585, Val Accuracy: 82.94%\n",
      "\n",
      "[4/100] Train Loss: 0.4303, Val Loss: 0.3879, Val Accuracy: 85.47%\n",
      "\n",
      "[5/100] Train Loss: 0.3714, Val Loss: 0.3505, Val Accuracy: 86.15%\n",
      "\n",
      "[6/100] Train Loss: 0.3448, Val Loss: 0.3286, Val Accuracy: 87.16%\n",
      "\n",
      "[7/100] Train Loss: 0.3319, Val Loss: 0.3196, Val Accuracy: 87.67%\n",
      "\n",
      "[8/100] Train Loss: 0.3223, Val Loss: 0.3098, Val Accuracy: 88.18%\n",
      "\n",
      "[9/100] Train Loss: 0.3223, Val Loss: 0.3098, Val Accuracy: 88.18%\n",
      "\n",
      "[10/100] Train Loss: 0.3223, Val Loss: 0.3098, Val Accuracy: 88.18%\n",
      "\n",
      "[11/100] Train Loss: 0.3223, Val Loss: 0.3098, Val Accuracy: 88.18%\n",
      "\n",
      "[12/100] Train Loss: 0.2860, Val Loss: 0.2862, Val Accuracy: 89.02%\n",
      "\n",
      "[13/100] Train Loss: 0.2860, Val Loss: 0.2862, Val Accuracy: 89.02%\n",
      "\n",
      "[14/100] Train Loss: 0.2860, Val Loss: 0.2862, Val Accuracy: 89.02%\n",
      "\n",
      "[15/100] Train Loss: 0.2860, Val Loss: 0.2862, Val Accuracy: 89.02%\n",
      "\n",
      "[16/100] Train Loss: 0.2860, Val Loss: 0.2862, Val Accuracy: 89.02%\n",
      "\n",
      "[17/100] Train Loss: 0.2860, Val Loss: 0.2862, Val Accuracy: 89.02%\n",
      "\n",
      "[18/100] Train Loss: 0.2860, Val Loss: 0.2862, Val Accuracy: 89.02%\n",
      "\n",
      "[19/100] Train Loss: 0.2546, Val Loss: 0.2795, Val Accuracy: 89.86%\n",
      "\n",
      "[20/100] Train Loss: 0.2546, Val Loss: 0.2795, Val Accuracy: 89.86%\n",
      "\n",
      "[21/100] Train Loss: 0.2546, Val Loss: 0.2795, Val Accuracy: 89.86%\n",
      "\n",
      "[22/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[23/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[24/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[25/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[26/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[27/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[28/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[29/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[30/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[31/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[32/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[33/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[34/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[35/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[36/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[37/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[38/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[39/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[40/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[41/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[42/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[43/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[44/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[45/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[46/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[47/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[48/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[49/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[50/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[51/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[52/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[53/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[54/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[55/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[56/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[57/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[58/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[59/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[60/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[61/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[62/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[63/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[64/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[65/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[66/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[67/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[68/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[69/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[70/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[71/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[72/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[73/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[74/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[75/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[76/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[77/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[78/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[79/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[80/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[81/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[82/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[83/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[84/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[85/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[86/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[87/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[88/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[89/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[90/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[91/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[92/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[93/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[94/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[95/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[96/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[97/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[98/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "[99/100] Train Loss: 0.2397, Val Loss: 0.2748, Val Accuracy: 90.03%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       259        |          34         |\n",
      "| true nonlenses |        28        |         272         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 89.5447% |\n",
      "|    loss   |  0.0055  |\n",
      "| auc score |  0.9590  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.9024  | 0.8840 |  0.8931 |   293   |\n",
      "|   nonlenses    |   0.8889  | 0.9067 |  0.8977 |   300   |\n",
      "| macro averaged |   0.8957  | 0.8953 |  0.8954 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 28\n",
      "lr: 1e-07, momentum: 0.9, weight_decay: 0.0, num_epochs: 100\n",
      "\n",
      "[0/100] Train Loss: 0.5817, Val Loss: 0.5491, Val Accuracy: 73.65%\n",
      "\n",
      "[1/100] Train Loss: 0.5629, Val Loss: 0.5277, Val Accuracy: 76.35%\n",
      "\n",
      "[2/100] Train Loss: 0.5466, Val Loss: 0.5104, Val Accuracy: 77.87%\n",
      "\n",
      "[3/100] Train Loss: 0.5327, Val Loss: 0.4962, Val Accuracy: 78.89%\n",
      "\n",
      "[4/100] Train Loss: 0.5214, Val Loss: 0.4835, Val Accuracy: 79.39%\n",
      "\n",
      "[5/100] Train Loss: 0.5118, Val Loss: 0.4733, Val Accuracy: 79.90%\n",
      "\n",
      "[6/100] Train Loss: 0.5023, Val Loss: 0.4644, Val Accuracy: 80.07%\n",
      "\n",
      "[7/100] Train Loss: 0.5023, Val Loss: 0.4644, Val Accuracy: 80.07%\n",
      "\n",
      "[8/100] Train Loss: 0.4846, Val Loss: 0.4497, Val Accuracy: 80.74%\n",
      "\n",
      "[9/100] Train Loss: 0.4788, Val Loss: 0.4435, Val Accuracy: 81.42%\n",
      "\n",
      "[10/100] Train Loss: 0.4739, Val Loss: 0.4379, Val Accuracy: 82.26%\n",
      "\n",
      "[11/100] Train Loss: 0.4739, Val Loss: 0.4379, Val Accuracy: 82.26%\n",
      "\n",
      "[12/100] Train Loss: 0.4630, Val Loss: 0.4283, Val Accuracy: 82.60%\n",
      "\n",
      "[13/100] Train Loss: 0.4583, Val Loss: 0.4245, Val Accuracy: 82.94%\n",
      "\n",
      "[14/100] Train Loss: 0.4583, Val Loss: 0.4245, Val Accuracy: 82.94%\n",
      "\n",
      "[15/100] Train Loss: 0.4480, Val Loss: 0.4172, Val Accuracy: 83.11%\n",
      "\n",
      "[16/100] Train Loss: 0.4450, Val Loss: 0.4140, Val Accuracy: 83.45%\n",
      "\n",
      "[17/100] Train Loss: 0.4450, Val Loss: 0.4140, Val Accuracy: 83.45%\n",
      "\n",
      "[18/100] Train Loss: 0.4450, Val Loss: 0.4140, Val Accuracy: 83.45%\n",
      "\n",
      "[19/100] Train Loss: 0.4450, Val Loss: 0.4140, Val Accuracy: 83.45%\n",
      "\n",
      "[20/100] Train Loss: 0.4450, Val Loss: 0.4140, Val Accuracy: 83.45%\n",
      "\n",
      "[21/100] Train Loss: 0.4450, Val Loss: 0.4140, Val Accuracy: 83.45%\n",
      "\n",
      "[22/100] Train Loss: 0.4450, Val Loss: 0.4140, Val Accuracy: 83.45%\n",
      "\n",
      "[23/100] Train Loss: 0.4450, Val Loss: 0.4140, Val Accuracy: 83.45%\n",
      "\n",
      "[24/100] Train Loss: 0.4166, Val Loss: 0.3950, Val Accuracy: 83.61%\n",
      "\n",
      "[25/100] Train Loss: 0.4171, Val Loss: 0.3931, Val Accuracy: 83.95%\n",
      "\n",
      "[26/100] Train Loss: 0.4171, Val Loss: 0.3931, Val Accuracy: 83.95%\n",
      "\n",
      "[27/100] Train Loss: 0.4113, Val Loss: 0.3915, Val Accuracy: 84.12%\n",
      "\n",
      "[28/100] Train Loss: 0.4113, Val Loss: 0.3915, Val Accuracy: 84.12%\n",
      "\n",
      "[29/100] Train Loss: 0.4113, Val Loss: 0.3915, Val Accuracy: 84.12%\n",
      "\n",
      "[30/100] Train Loss: 0.4113, Val Loss: 0.3915, Val Accuracy: 84.12%\n",
      "\n",
      "[31/100] Train Loss: 0.4113, Val Loss: 0.3915, Val Accuracy: 84.12%\n",
      "\n",
      "[32/100] Train Loss: 0.4113, Val Loss: 0.3915, Val Accuracy: 84.12%\n",
      "\n",
      "[33/100] Train Loss: 0.4113, Val Loss: 0.3915, Val Accuracy: 84.12%\n",
      "\n",
      "[34/100] Train Loss: 0.4113, Val Loss: 0.3915, Val Accuracy: 84.12%\n",
      "\n",
      "[35/100] Train Loss: 0.4113, Val Loss: 0.3915, Val Accuracy: 84.12%\n",
      "\n",
      "[36/100] Train Loss: 0.4113, Val Loss: 0.3915, Val Accuracy: 84.12%\n",
      "\n",
      "[37/100] Train Loss: 0.4113, Val Loss: 0.3915, Val Accuracy: 84.12%\n",
      "\n",
      "[38/100] Train Loss: 0.4113, Val Loss: 0.3915, Val Accuracy: 84.12%\n",
      "\n",
      "[39/100] Train Loss: 0.3880, Val Loss: 0.3770, Val Accuracy: 84.29%\n",
      "\n",
      "[40/100] Train Loss: 0.3880, Val Loss: 0.3770, Val Accuracy: 84.29%\n",
      "\n",
      "[41/100] Train Loss: 0.3880, Val Loss: 0.3770, Val Accuracy: 84.29%\n",
      "\n",
      "[42/100] Train Loss: 0.3827, Val Loss: 0.3745, Val Accuracy: 84.46%\n",
      "\n",
      "[43/100] Train Loss: 0.3822, Val Loss: 0.3736, Val Accuracy: 84.63%\n",
      "\n",
      "[44/100] Train Loss: 0.3822, Val Loss: 0.3736, Val Accuracy: 84.63%\n",
      "\n",
      "[45/100] Train Loss: 0.3822, Val Loss: 0.3736, Val Accuracy: 84.63%\n",
      "\n",
      "[46/100] Train Loss: 0.3822, Val Loss: 0.3736, Val Accuracy: 84.63%\n",
      "\n",
      "[47/100] Train Loss: 0.3822, Val Loss: 0.3736, Val Accuracy: 84.63%\n",
      "\n",
      "[48/100] Train Loss: 0.3822, Val Loss: 0.3736, Val Accuracy: 84.63%\n",
      "\n",
      "[49/100] Train Loss: 0.3746, Val Loss: 0.3696, Val Accuracy: 84.80%\n",
      "\n",
      "[50/100] Train Loss: 0.3746, Val Loss: 0.3696, Val Accuracy: 84.80%\n",
      "\n",
      "[51/100] Train Loss: 0.3746, Val Loss: 0.3696, Val Accuracy: 84.80%\n",
      "\n",
      "[52/100] Train Loss: 0.3746, Val Loss: 0.3696, Val Accuracy: 84.80%\n",
      "\n",
      "[53/100] Train Loss: 0.3746, Val Loss: 0.3696, Val Accuracy: 84.80%\n",
      "\n",
      "[54/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[55/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[56/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[57/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[58/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[59/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[60/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[61/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[62/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[63/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[64/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[65/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[66/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[67/100] Train Loss: 0.3731, Val Loss: 0.3669, Val Accuracy: 84.97%\n",
      "\n",
      "[68/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[69/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[70/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[71/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[72/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[73/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[74/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[75/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[76/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[77/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[78/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[79/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[80/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[81/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[82/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[83/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[84/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[85/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[86/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[87/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[88/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[89/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[90/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[91/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[92/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[93/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[94/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[95/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[96/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[97/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[98/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "[99/100] Train Loss: 0.3642, Val Loss: 0.3623, Val Accuracy: 85.14%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       248        |          45         |\n",
      "| true nonlenses |        48        |         252         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 84.3170% |\n",
      "|    loss   |  0.0160  |\n",
      "| auc score |  0.9094  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8378  | 0.8464 |  0.8421 |   293   |\n",
      "|   nonlenses    |   0.8485  | 0.8400 |  0.8442 |   300   |\n",
      "| macro averaged |   0.8432  | 0.8432 |  0.8432 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 29\n",
      "lr: 0.0001, momentum: 0.9, weight_decay: 0.0005, num_epochs: 100\n",
      "\n",
      "[0/100] Train Loss: 0.3735, Val Loss: 0.2792, Val Accuracy: 87.67%\n",
      "\n",
      "[1/100] Train Loss: 0.2813, Val Loss: 0.2698, Val Accuracy: 89.70%\n",
      "\n",
      "[2/100] Train Loss: 0.2813, Val Loss: 0.2698, Val Accuracy: 89.70%\n",
      "\n",
      "[3/100] Train Loss: 0.2527, Val Loss: 0.2369, Val Accuracy: 90.88%\n",
      "\n",
      "[4/100] Train Loss: 0.2527, Val Loss: 0.2369, Val Accuracy: 90.88%\n",
      "\n",
      "[5/100] Train Loss: 0.2527, Val Loss: 0.2369, Val Accuracy: 90.88%\n",
      "\n",
      "[6/100] Train Loss: 0.2527, Val Loss: 0.2369, Val Accuracy: 90.88%\n",
      "\n",
      "[7/100] Train Loss: 0.2527, Val Loss: 0.2369, Val Accuracy: 90.88%\n",
      "\n",
      "[8/100] Train Loss: 0.2527, Val Loss: 0.2369, Val Accuracy: 90.88%\n",
      "\n",
      "[9/100] Train Loss: 0.2527, Val Loss: 0.2369, Val Accuracy: 90.88%\n",
      "\n",
      "[10/100] Train Loss: 0.2527, Val Loss: 0.2369, Val Accuracy: 90.88%\n",
      "\n",
      "[11/100] Train Loss: 0.2527, Val Loss: 0.2369, Val Accuracy: 90.88%\n",
      "\n",
      "[12/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[13/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[14/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[15/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[16/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[17/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[18/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[19/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[20/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[21/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[22/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[23/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[24/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[25/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[26/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[27/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[28/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[29/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[30/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[31/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[32/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[33/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[34/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[35/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[36/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[37/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[38/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[39/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[40/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[41/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[42/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[43/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[44/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[45/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[46/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[47/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[48/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[49/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[50/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[51/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[52/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[53/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[54/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[55/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[56/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[57/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[58/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[59/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[60/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[61/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[62/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[63/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[64/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[65/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[66/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[67/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[68/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[69/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[70/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[71/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[72/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[73/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[74/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[75/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[76/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[77/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[78/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[79/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[80/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[81/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[82/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[83/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[84/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[85/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[86/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[87/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[88/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[89/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[90/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[91/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[92/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[93/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[94/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[95/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[96/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[97/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[98/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "[99/100] Train Loss: 0.0925, Val Loss: 0.2223, Val Accuracy: 91.89%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       257        |          36         |\n",
      "| true nonlenses |        21        |         279         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 90.3879% |\n",
      "|    loss   |  0.0032  |\n",
      "| auc score |  0.9659  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.9245  | 0.8771 |  0.9002 |   293   |\n",
      "|   nonlenses    |   0.8857  | 0.9300 |  0.9073 |   300   |\n",
      "| macro averaged |   0.9051  | 0.9036 |  0.9037 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "Iter 30\n",
      "lr: 1e-05, momentum: 0.9, weight_decay: 0.0005, num_epochs: 100\n",
      "\n",
      "[0/100] Train Loss: 0.4087, Val Loss: 0.3177, Val Accuracy: 87.33%\n",
      "\n",
      "[1/100] Train Loss: 0.4087, Val Loss: 0.3177, Val Accuracy: 87.33%\n",
      "\n",
      "[2/100] Train Loss: 0.2799, Val Loss: 0.2619, Val Accuracy: 88.85%\n",
      "\n",
      "[3/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[4/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[5/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[6/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[7/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[8/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[9/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[10/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[11/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[12/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[13/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[14/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[15/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[16/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[17/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[18/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[19/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[20/100] Train Loss: 0.2590, Val Loss: 0.2489, Val Accuracy: 90.37%\n",
      "\n",
      "[21/100] Train Loss: 0.0334, Val Loss: 0.4023, Val Accuracy: 90.71%\n",
      "\n",
      "[22/100] Train Loss: 0.0334, Val Loss: 0.4023, Val Accuracy: 90.71%\n",
      "\n",
      "[23/100] Train Loss: 0.0334, Val Loss: 0.4023, Val Accuracy: 90.71%\n",
      "\n",
      "[24/100] Train Loss: 0.0334, Val Loss: 0.4023, Val Accuracy: 90.71%\n",
      "\n",
      "[25/100] Train Loss: 0.0334, Val Loss: 0.4023, Val Accuracy: 90.71%\n",
      "\n",
      "[26/100] Train Loss: 0.0334, Val Loss: 0.4023, Val Accuracy: 90.71%\n",
      "\n",
      "[27/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[28/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[29/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[30/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[31/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[32/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[33/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[34/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[35/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[36/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[37/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[38/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[39/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[40/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[41/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[42/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[43/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[44/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[45/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[46/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[47/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[48/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[49/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[50/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[51/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[52/100] Train Loss: 0.0172, Val Loss: 0.4208, Val Accuracy: 90.88%\n",
      "\n",
      "[53/100] Train Loss: 0.0071, Val Loss: 0.4680, Val Accuracy: 91.05%\n",
      "\n",
      "[54/100] Train Loss: 0.0071, Val Loss: 0.4680, Val Accuracy: 91.05%\n",
      "\n",
      "[55/100] Train Loss: 0.0071, Val Loss: 0.4680, Val Accuracy: 91.05%\n",
      "\n",
      "[56/100] Train Loss: 0.0071, Val Loss: 0.4680, Val Accuracy: 91.05%\n",
      "\n",
      "[57/100] Train Loss: 0.0071, Val Loss: 0.4680, Val Accuracy: 91.05%\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m momentum \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.9\u001b[39m]\n\u001b[1;32m     12\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mhyperparam_grid_finetune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_transforms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meval_transforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m384\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gsoc24/ssl/working/0606/expt13-20240607-172146/../../../ssl/utils/eval.py:198\u001b[0m, in \u001b[0;36mhyperparam_grid_finetune\u001b[0;34m(ckpt_path, eval_transforms, embed_dim, num_epochs, lr, momentum, weight_decay, data_path)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhyperparam_grid_finetune\u001b[39m(\n\u001b[1;32m    189\u001b[0m         ckpt_path, \n\u001b[1;32m    190\u001b[0m         eval_transforms,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m         data_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../input/real_lenses_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    197\u001b[0m     ):\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hyperparam_grid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m                    \u001b[49m\u001b[43meval_transforms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meval_transforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m                    \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinetune\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    208\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gsoc24/ssl/working/0606/expt13-20240607-172146/../../../ssl/utils/eval.py:173\u001b[0m, in \u001b[0;36m_hyperparam_grid\u001b[0;34m(ckpt_path, eval_transforms, embed_dim, num_epochs, lr, momentum, weight_decay, data_path, net, mode)\u001b[0m\n\u001b[1;32m    171\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m    172\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(optimizer, T_max\u001b[38;5;241m=\u001b[39mnum_epochs, eta_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 173\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_transforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m test_model(model, ckpt_path, eval_transforms, criterion, data_path)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/gsoc24/ssl/working/0606/expt13-20240607-172146/../../../ssl/utils/eval.py:83\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, ckpt_path, eval_transforms, num_epochs, optimizer, scheduler, criterion, data_path)\u001b[0m\n\u001b[1;32m     81\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mcuda(), labels\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     82\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 83\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mflatten(), labels\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat))\n\u001b[1;32m     85\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gsoc24/ssl/working/0606/expt13-20240607-172146/../../../ssl/models/MLP.py:24\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(x)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[0;32m---> 24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gsoc24/ssl/working/0606/expt13-20240607-172146/../../../ssl/models/vit.py:265\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    262\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolate_pos_encoding(x, W, H)\n\u001b[1;32m    263\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_drop(x)\n\u001b[0;32m--> 265\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_layer(x)\n\u001b[1;32m    268\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# class token\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gsoc24/ssl/working/0606/expt13-20240607-172146/../../../ssl/models/vit.py:138\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 138\u001b[0m     y, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     x \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path1(y)\n\u001b[1;32m    140\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x)))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gsoc24/ssl/working/0606/expt13-20240607-172146/../../../ssl/models/vit.py:43\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m q \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n\u001b[1;32m     42\u001b[0m attn \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_drop(attn)\n\u001b[1;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m (attn \u001b[38;5;241m@\u001b[39m v)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B, N, C)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_transforms = Transforms.Compose([\n",
    "                                Transforms.CenterCrop(64),\n",
    "                                MinMaxScaling(),\n",
    "                                Transforms.Normalize([0.5107012987136841, 0.530750572681427, 0.5519816279411316],\n",
    "                                                     [0.022646993398666382, 0.059592872858047485, 0.08994007110595703]),\n",
    "                            ])\n",
    "data_path = \"../../../input/real_lenses_dataset\"\n",
    "\n",
    "lr = [1e-4, 1e-5, 1e-6, 1e-7]\n",
    "weight_decay = [0, 5e-4, 5e-5]\n",
    "momentum = [0.9]\n",
    "num_epochs = [20, 50, 100]\n",
    "\n",
    "best_params = hyperparam_grid_finetune(\n",
    "                ckpt_path=ckpt_path,\n",
    "                eval_transforms = eval_transforms,\n",
    "                embed_dim = 384,\n",
    "                num_epochs = num_epochs,\n",
    "                lr = lr,\n",
    "                momentum = momentum,\n",
    "                weight_decay = weight_decay,\n",
    "                data_path = data_path,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41fb0097-ea04-4048-b5a0-4fbcbd9e2c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================\n",
      "Iter 1\n",
      "lr: 1e-05, momentum: 0.9, weight_decay: 0.0, num_epochs: 20\n",
      "\n",
      "[0/20] Train Loss: 0.4628, Val Loss: 0.3380, Val Accuracy: 86.15%\n",
      "\n",
      "[1/20] Train Loss: 0.3311, Val Loss: 0.3005, Val Accuracy: 88.68%\n",
      "\n",
      "[2/20] Train Loss: 0.2820, Val Loss: 0.2723, Val Accuracy: 90.03%\n",
      "\n",
      "[3/20] Train Loss: 0.2820, Val Loss: 0.2723, Val Accuracy: 90.03%\n",
      "\n",
      "[4/20] Train Loss: 0.2820, Val Loss: 0.2723, Val Accuracy: 90.03%\n",
      "\n",
      "[5/20] Train Loss: 0.2820, Val Loss: 0.2723, Val Accuracy: 90.03%\n",
      "\n",
      "[6/20] Train Loss: 0.2820, Val Loss: 0.2723, Val Accuracy: 90.03%\n",
      "\n",
      "[7/20] Train Loss: 0.2820, Val Loss: 0.2723, Val Accuracy: 90.03%\n",
      "\n",
      "[8/20] Train Loss: 0.1480, Val Loss: 0.2378, Val Accuracy: 91.05%\n",
      "\n",
      "[9/20] Train Loss: 0.1480, Val Loss: 0.2378, Val Accuracy: 91.05%\n",
      "\n",
      "[10/20] Train Loss: 0.1480, Val Loss: 0.2378, Val Accuracy: 91.05%\n",
      "\n",
      "[11/20] Train Loss: 0.1480, Val Loss: 0.2378, Val Accuracy: 91.05%\n",
      "\n",
      "[12/20] Train Loss: 0.1480, Val Loss: 0.2378, Val Accuracy: 91.05%\n",
      "\n",
      "[13/20] Train Loss: 0.1480, Val Loss: 0.2378, Val Accuracy: 91.05%\n",
      "\n",
      "[14/20] Train Loss: 0.1480, Val Loss: 0.2378, Val Accuracy: 91.05%\n",
      "\n",
      "[15/20] Train Loss: 0.1480, Val Loss: 0.2378, Val Accuracy: 91.05%\n",
      "\n",
      "[16/20] Train Loss: 0.1480, Val Loss: 0.2378, Val Accuracy: 91.05%\n",
      "\n",
      "[17/20] Train Loss: 0.1480, Val Loss: 0.2378, Val Accuracy: 91.05%\n",
      "\n",
      "[18/20] Train Loss: 0.1480, Val Loss: 0.2378, Val Accuracy: 91.05%\n",
      "\n",
      "[19/20] Train Loss: 0.1480, Val Loss: 0.2378, Val Accuracy: 91.05%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       262        |          31         |\n",
      "| true nonlenses |        32        |         268         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 89.3761% |\n",
      "|    loss   |  0.0024  |\n",
      "| auc score |  0.9569  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.8912  | 0.8942 |  0.8927 |   293   |\n",
      "|   nonlenses    |   0.8963  | 0.8933 |  0.8948 |   300   |\n",
      "| macro averaged |   0.8937  | 0.8938 |  0.8937 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "================================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_transforms = Transforms.Compose([\n",
    "                                Transforms.CenterCrop(64),\n",
    "                                MinMaxScaling(),\n",
    "                                Transforms.Normalize([0.5107012987136841, 0.530750572681427, 0.5519816279411316],\n",
    "                                                     [0.022646993398666382, 0.059592872858047485, 0.08994007110595703]),\n",
    "                            ])\n",
    "data_path = \"../../../input/real_lenses_dataset\"\n",
    "\n",
    "lr = [1e-5]\n",
    "weight_decay = [0]\n",
    "momentum = [0.9]\n",
    "num_epochs = [20]\n",
    "\n",
    "best_params = hyperparam_grid_finetune(\n",
    "                ckpt_path=ckpt_path,\n",
    "                eval_transforms = eval_transforms,\n",
    "                embed_dim = 384,\n",
    "                num_epochs = num_epochs,\n",
    "                lr = lr,\n",
    "                momentum = momentum,\n",
    "                weight_decay = weight_decay,\n",
    "                data_path = data_path,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdeb9cf9-176c-4536-8b6c-890d430433b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MinMaxScaling:\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             min_clamp = -3.,\n",
    "#             max_clamp = 3.,\n",
    "#         ):\n",
    "#         self.min_clamp = min_clamp\n",
    "#         self.max_clamp = max_clamp\n",
    "        \n",
    "#     def __call__(self, img):\n",
    "#         img = torch.clamp(img, min=self.min_clamp, max=self.max_clamp)\n",
    "#         C, H, W = img.shape \n",
    "\n",
    "#         max = torch.full_like(img, self.max_clamp)\n",
    "#         # c = torch.reshape(img, (C, -1)).max(-1).values\n",
    "#         # for i in range(C):\n",
    "#         #     max[i] = c[i]\n",
    "        \n",
    "#         min = torch.full_like(img, self.min_clamp)\n",
    "#         # c = torch.reshape(img, (C, -1)).min(-1).values\n",
    "#         # for i in range(C):\n",
    "#         #     min[i] = c[i]\n",
    "        \n",
    "#         x = max - min\n",
    "#         # x = x + torch.full_like(x, 1e-8)\n",
    "#         return (img - min) / x\n",
    "#         # return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae3ea7ce-acb2-4e6d-bfe2-0292657772f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/20] Train Loss: 0.3945, Val Loss: 0.2975, Val Accuracy: 86.82%\n",
      "\n",
      "[2/20] Train Loss: 0.2952, Val Loss: 0.3116, Val Accuracy: 89.70%\n",
      "\n",
      "[3/20] Train Loss: 0.2952, Val Loss: 0.3116, Val Accuracy: 89.70%\n",
      "\n",
      "[4/20] Train Loss: 0.2952, Val Loss: 0.3116, Val Accuracy: 89.70%\n",
      "\n",
      "[5/20] Train Loss: 0.2952, Val Loss: 0.3116, Val Accuracy: 89.70%\n",
      "\n",
      "[6/20] Train Loss: 0.2952, Val Loss: 0.3116, Val Accuracy: 89.70%\n",
      "\n",
      "[7/20] Train Loss: 0.1837, Val Loss: 0.2904, Val Accuracy: 90.20%\n",
      "\n",
      "[8/20] Train Loss: 0.1580, Val Loss: 0.2289, Val Accuracy: 90.54%\n",
      "\n",
      "[9/20] Train Loss: 0.1373, Val Loss: 0.2589, Val Accuracy: 90.71%\n",
      "\n",
      "[10/20] Train Loss: 0.1373, Val Loss: 0.2589, Val Accuracy: 90.71%\n",
      "\n",
      "[11/20] Train Loss: 0.1093, Val Loss: 0.2990, Val Accuracy: 91.05%\n",
      "\n",
      "[12/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[13/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[14/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[15/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[16/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[17/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[18/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[19/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "[20/20] Train Loss: 0.0732, Val Loss: 0.3254, Val Accuracy: 91.55%\n",
      "\n",
      "Evaluation on held out test dataset\n",
      "Confusion Matrix\n",
      "+----------------+------------------+---------------------+\n",
      "|                | predicted lenses | predicted nonlenses |\n",
      "+----------------+------------------+---------------------+\n",
      "|  true lenses   |       260        |          33         |\n",
      "| true nonlenses |        23        |         277         |\n",
      "+----------------+------------------+---------------------+\n",
      "Test Metrics\n",
      "+-----------+----------+\n",
      "|  accuracy | 90.5565% |\n",
      "|    loss   |  0.0067  |\n",
      "| auc score |  0.9705  |\n",
      "+-----------+----------+\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|                | precision | recall | f-score | support |\n",
      "+----------------+-----------+--------+---------+---------+\n",
      "|     lenses     |   0.9187  | 0.8874 |  0.9028 |   293   |\n",
      "|   nonlenses    |   0.8935  | 0.9233 |  0.9082 |   300   |\n",
      "| macro averaged |   0.9061  | 0.9054 |  0.9055 |         |\n",
      "+----------------+-----------+--------+---------+---------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0067, device='cuda:0', grad_fn=<DivBackward0>), 90.55649241146712)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models.MLP import MLP\n",
    "from utils.eval import train\n",
    "from utils.eval import test_model\n",
    "\n",
    "set_seed(12)\n",
    "\n",
    "state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "model = MLP(\n",
    "    copy.deepcopy(state[\"student\"].backbone),\n",
    "    embed_dim = 384,\n",
    "    output_dim = 1,\n",
    "    freeze_backbone = False,\n",
    ")\n",
    "torch.nn.init.xavier_uniform_(model.fc.weight)\n",
    "model.fc.bias.data.fill_(0.01)\n",
    "\n",
    "model = model.cuda()\n",
    "model.train()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4,weight_decay=0)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0)\n",
    "\n",
    "eval_transforms = Transforms.Compose([\n",
    "                                Transforms.CenterCrop(64),\n",
    "                                MinMaxScaling(),\n",
    "                                Transforms.Normalize([0.5107012987136841, 0.530750572681427, 0.5519816279411316],\n",
    "                                                     [0.022646993398666382, 0.059592872858047485, 0.08994007110595703]),\n",
    "                            ])\n",
    "data_path = \"../../../input/real_lenses_dataset\"\n",
    "\n",
    "model = train(\n",
    "        model,\n",
    "        ckpt_path,\n",
    "        eval_transforms,\n",
    "        20, \n",
    "        optimizer, \n",
    "        scheduler,\n",
    "        criterion,\n",
    "        data_path,\n",
    "        batch_size=32\n",
    "    )\n",
    "test_model(model, ckpt_path, eval_transforms, criterion, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c04700dd-3228-4385-8a30-28f55fb4c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./ViT_S_16_classification.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6489661f-7b0a-46c6-9dc1-be6d1d2098b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_path = \"../../../input/real_lenses_dataset\"\n",
    "state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "def npy_loader(path):\n",
    "    sample = torch.from_numpy(np.load(path))\n",
    "    return sample\n",
    "    \n",
    "# regenerate the datasets\n",
    "test_indices = state[\"history\"][\"test_indices\"]\n",
    "\n",
    "\n",
    "dataset = datasets.DatasetFolder(\n",
    "        root=data_path,\n",
    "        loader=npy_loader,\n",
    "        extensions=['.npy'],\n",
    "        transform=eval_transforms\n",
    "    )\n",
    "dataset.samples = [dataset.samples[i] for i in test_indices.indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9a7bb4f-849e-4c50-b451-6fabf39bfd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrongs = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    with torch.no_grad():\n",
    "        x = dataset[i][0]\n",
    "        C, H, W = x.shape\n",
    "        x = x.reshape(1, C, H, W).cuda()\n",
    "        y = model(x)\n",
    "        y = (y.cpu().numpy().ravel() > 0).astype(np.float16)\n",
    "        label = float(dataset[i][1])\n",
    "        if y != label:\n",
    "            wrongs.append(dataset[i][0])        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98dc32ce-dfda-495b-a2d9-7815df99bd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.9813)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89360fd-f634-41ad-b60b-add4733d83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_backbone = False\n",
    "model.backbone.requires_grad = True\n",
    "\n",
    "model.train()\n",
    "\n",
    "model = model.cuda()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, eta_min=0)\n",
    "\n",
    "eval_transforms = Transforms.Compose([\n",
    "                                Transforms.CenterCrop(64),\n",
    "                                MinMaxScaling(),\n",
    "                                Transforms.Normalize([0.5107012987136841, 0.530750572681427, 0.5519816279411316],\n",
    "                                                     [0.022646993398666382, 0.059592872858047485, 0.08994007110595703]),\n",
    "                            ])\n",
    "data_path = \"../../../input/real_lenses_dataset\"\n",
    "\n",
    "model = train(\n",
    "        model,\n",
    "        ckpt_path,\n",
    "        eval_transforms,\n",
    "        40, \n",
    "        optimizer, \n",
    "        scheduler,\n",
    "        criterion,\n",
    "        data_path,\n",
    "    )\n",
    "\n",
    "test_model(model, ckpt_path, eval_transforms, criterion, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e007e-9655-4593-ba80-f719b1316e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e7c55-2ce2-46f7-b2dd-7d054a6960d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
